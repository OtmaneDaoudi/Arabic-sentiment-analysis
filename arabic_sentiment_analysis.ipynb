{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OtmaneDaoudi/Arabic-sentiment-analysis/blob/main/arabic_sentiment_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "YCMH2OjBGA8u"
      },
      "source": [
        "# Installing dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6BqPG4jsGF8m",
        "outputId": "71519abe-6ccb-4059-c163-edb45164bcbe"
      },
      "outputs": [],
      "source": [
        "# !pip install emoji\n",
        "# !pip install Arabic-Stopwords\n",
        "# !pip install seaborn\n",
        "# !pip install matplotlib\n",
        "# !pip install soyclustering"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "KUh0GecqEErv"
      },
      "source": [
        "# Libs imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "sQdYY3KPEEsC"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\asus\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import re\n",
        "import nltk\n",
        "import emoji\n",
        "import pickle\n",
        "import openpyxl\n",
        "\n",
        "import arabicstopwords.arabicstopwords as stp\n",
        "import pandas as pd\n",
        "import pyarabic.araby as araby\n",
        "import numpy as np \n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from snowballstemmer import stemmer\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "from typing import List\n",
        "\n",
        "nltk.download('stopwords')\n",
        "\n",
        "SEED = 21"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Importing data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676
        },
        "id": "MvI6l3cnEEsH",
        "outputId": "840f53a3-1120-4709-a395-10f90977c0a9"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>class</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>33372</th>\n",
              "      <td>pos</td>\n",
              "      <td>بخاخ فيجا الالماني انتصاب وتاخير دون تخدير</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41159</th>\n",
              "      <td>pos</td>\n",
              "      <td>شهور و يوم تعال خذ الزرقاء من فريق التماسيح</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18029</th>\n",
              "      <td>neg</td>\n",
              "      <td>⛔ طريق #الدمام × #الخبر ابعدواا عنه 📣</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37264</th>\n",
              "      <td>pos</td>\n",
              "      <td>احلى صباح 😂</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35690</th>\n",
              "      <td>pos</td>\n",
              "      <td>مع بعض الأصدقاء 💕 شاطئ فلامنغو ، أروبا</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44109</th>\n",
              "      <td>pos</td>\n",
              "      <td>ايوه صح بس ماتاخذني لمكان بعيد زيه 😂</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24380</th>\n",
              "      <td>pos</td>\n",
              "      <td>صباحك خير وبركة نجاة 🌺 💗 🌹</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23661</th>\n",
              "      <td>pos</td>\n",
              "      <td>تحية إلي أهل #ليبيا الكل وياعن دين زك أم اللي ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39242</th>\n",
              "      <td>pos</td>\n",
              "      <td>ماعرفتك وانت لبناني 😅</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42630</th>\n",
              "      <td>pos</td>\n",
              "      <td>سبحان الله الحمد لله لاإله الاالله الله أكبر ل...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22367</th>\n",
              "      <td>neg</td>\n",
              "      <td>راح بعثره وجاء فهد وطر جيبي 😯</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34645</th>\n",
              "      <td>pos</td>\n",
              "      <td>بمناسبة فوز الهلال .. 💙 سحب على آيفون XR📱 رتوي...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29356</th>\n",
              "      <td>pos</td>\n",
              "      <td>وضع الدوري هالسنه 😁</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7236</th>\n",
              "      <td>neg</td>\n",
              "      <td>ع اي اش اله علاقة بالطول 🌚</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44732</th>\n",
              "      <td>pos</td>\n",
              "      <td>اغبى موقف حلمانه بشخص وتقعدين تدورين عليه 😀</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3552</th>\n",
              "      <td>neg</td>\n",
              "      <td>عبدالله بالله ريتويت صدقة عن امي في هذا الليلة...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4152</th>\n",
              "      <td>neg</td>\n",
              "      <td>واحد تبع النظام السوري يقول أن المخابرات السور...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26120</th>\n",
              "      <td>pos</td>\n",
              "      <td>كلمه وحده تعبر عن شعوري حاليا: وييعع 🙂</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24570</th>\n",
              "      <td>pos</td>\n",
              "      <td>حسب توقيتكم انا مواصل ما نمت لما انام واصحى يص...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19035</th>\n",
              "      <td>neg</td>\n",
              "      <td>تبا ل خفاق مايرضا ب أحد غيرك كنه عشانك من ديار...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      class                                              tweet\n",
              "33372   pos         بخاخ فيجا الالماني انتصاب وتاخير دون تخدير\n",
              "41159   pos        شهور و يوم تعال خذ الزرقاء من فريق التماسيح\n",
              "18029   neg              ⛔ طريق #الدمام × #الخبر ابعدواا عنه 📣\n",
              "37264   pos                                        احلى صباح 😂\n",
              "35690   pos             مع بعض الأصدقاء 💕 شاطئ فلامنغو ، أروبا\n",
              "44109   pos               ايوه صح بس ماتاخذني لمكان بعيد زيه 😂\n",
              "24380   pos                         صباحك خير وبركة نجاة 🌺 💗 🌹\n",
              "23661   pos  تحية إلي أهل #ليبيا الكل وياعن دين زك أم اللي ...\n",
              "39242   pos                              ماعرفتك وانت لبناني 😅\n",
              "42630   pos  سبحان الله الحمد لله لاإله الاالله الله أكبر ل...\n",
              "22367   neg                      راح بعثره وجاء فهد وطر جيبي 😯\n",
              "34645   pos  بمناسبة فوز الهلال .. 💙 سحب على آيفون XR📱 رتوي...\n",
              "29356   pos                                وضع الدوري هالسنه 😁\n",
              "7236    neg                         ع اي اش اله علاقة بالطول 🌚\n",
              "44732   pos        اغبى موقف حلمانه بشخص وتقعدين تدورين عليه 😀\n",
              "3552    neg  عبدالله بالله ريتويت صدقة عن امي في هذا الليلة...\n",
              "4152    neg  واحد تبع النظام السوري يقول أن المخابرات السور...\n",
              "26120   pos             كلمه وحده تعبر عن شعوري حاليا: وييعع 🙂\n",
              "24570   pos  حسب توقيتكم انا مواصل ما نمت لما انام واصحى يص...\n",
              "19035   neg  تبا ل خفاق مايرضا ب أحد غيرك كنه عشانك من ديار..."
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = pd.read_csv(\"./datasets/ASTC/data.tsv\", header = 0, sep='\\t', names = [\"class\", \"tweet\"]).sample(frac = 1, random_state = SEED)\n",
        "data.head(20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "fqggWownEEsK",
        "outputId": "e8a398e4-bfd2-44cf-b85f-2ea0ab850aa8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 45274 entries, 33372 to 15305\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   class   45274 non-null  object\n",
            " 1   tweet   45274 non-null  object\n",
            "dtypes: object(2)\n",
            "memory usage: 1.0+ MB\n"
          ]
        }
      ],
      "source": [
        "data.info()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "GIECLLDlEEsM"
      },
      "source": [
        "# Data preprocessing"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "NDtOpDzdEEsP"
      },
      "source": [
        "Our preprocessing pipeline contains the following steps:\n",
        "\n",
        "1.  Remove duplicat entries\n",
        "2.  Replacing emojies & emoticons\n",
        "3.  Remove mentions\n",
        "4.  Remove Links\n",
        "5.  Remove whitespaces\n",
        "6.  Remove punctuations & Special chars\n",
        "7.  Remove Consecutive characters\n",
        "8.  Tokenization\n",
        "9.  Remove foreign words\n",
        "10. Remove stop words\n",
        "11. Remove numbers\n",
        "12. Stemming\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "zolKP03vEEsT"
      },
      "source": [
        "## Removing duplicates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SeMI9vGpEEsW",
        "outputId": "e2fb0124-2a17-4db2-c06f-52d48a0b7000"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "34.7% of the data are duplicats\n"
          ]
        }
      ],
      "source": [
        "count = data.duplicated().sum()\n",
        "print(f\"{(count / data.shape[0]) * 100:.1f}% of the data are duplicats\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Ahlc7NfGEEsY"
      },
      "outputs": [],
      "source": [
        "data.drop_duplicates(inplace = True)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Jv54Q2aKEEsZ"
      },
      "source": [
        "## Replacing emojies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "75Dy9RLbEEsa"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>class</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>33372</th>\n",
              "      <td>pos</td>\n",
              "      <td>بخاخ فيجا الالماني انتصاب وتاخير دون تخدير</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41159</th>\n",
              "      <td>pos</td>\n",
              "      <td>شهور و يوم تعال خذ الزرقاء من فريق التماسيح</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18029</th>\n",
              "      <td>neg</td>\n",
              "      <td>حذر  طريق #الدمام × #الخبر ابعدواا عنه</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37264</th>\n",
              "      <td>pos</td>\n",
              "      <td>احلى صباح يضحك</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35690</th>\n",
              "      <td>pos</td>\n",
              "      <td>مع بعض الأصدقاء حب  شاطئ فلامنغو ، أروبا</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      class                                        tweet\n",
              "33372   pos   بخاخ فيجا الالماني انتصاب وتاخير دون تخدير\n",
              "41159   pos  شهور و يوم تعال خذ الزرقاء من فريق التماسيح\n",
              "18029   neg      حذر  طريق #الدمام × #الخبر ابعدواا عنه \n",
              "37264   pos                              احلى صباح يضحك \n",
              "35690   pos     مع بعض الأصدقاء حب  شاطئ فلامنغو ، أروبا"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "emojis = {\n",
        "    \"🙂\":\"يبتسم\",\n",
        "    \"😂\":\"يضحك\",\n",
        "    \"🤣\" : \"يضحك\",\n",
        "    \"💔\":\"قلب حزين\",\n",
        "    \"🙂\":\"يبتسم\",\n",
        "    \"❤️\":\"حب\",\n",
        "    \"🥰\":\"حب\",\n",
        "    \"🤐\":\"سكوت\",\n",
        "    \"🧡\":\"حب\",\n",
        "    \"❤\":\"حب\",\n",
        "    \"😍\":\"حب\",\n",
        "    \"😭\":\"يبكي\",\n",
        "    \"🤭\":\"يبتسم\",\n",
        "    \"😢\":\"حزن\",\n",
        "    \"😔\":\"حزن\",\n",
        "    \"♥\":\"حب\",\n",
        "    \"💜\":\"حب\",\n",
        "    \"😅\":\"يضحك\",\n",
        "    \"🙁\":\"حزين\",\n",
        "    \"💕\":\"حب\",\n",
        "    \"💙\":\"حب\",\n",
        "    \"😞\":\"حزين\",\n",
        "    \"😊\":\"سعادة\",\n",
        "    \"👏\":\"يصفق\",\n",
        "    \"👌\":\"احسنت\",\n",
        "    \"😴\":\"ينام\",\n",
        "    \"😀\":\"يضحك\",\n",
        "    \"✅\":\"صحيح\",\n",
        "    \"🤪\":\"يضحك\",\n",
        "    \"🏡\" : \"بيت\",\n",
        "    \"🤲\" : \"دعاء\",\n",
        "    \"💰\" : \"مال\",\n",
        "    \"😌\":\"حزين\",\n",
        "    \"🎁\":\"هدية\",\n",
        "    \"🌹\":\"وردة\",\n",
        "    \"🥀\":\"وردة\",\n",
        "    \"📿\":\"وردة\",\n",
        "    \"✍\":\"كتابة\",\n",
        "    \"🙈\":\"حب\",\n",
        "    \"😄\":\"يضحك\",\n",
        "    \"😐\":\"محايد\",\n",
        "    \"✌\":\"منتصر\",\n",
        "    \"✨\":\"نجمه\",\n",
        "    \"🤔\":\"تفكير\",\n",
        "    \"😏\":\"يستهزء\",\n",
        "    \"😒\":\"يستهزء\",\n",
        "    \"🙄\":\"ملل\",\n",
        "    \"😕\":\"عصبية\",\n",
        "    \"😃\":\"يضحك\",\n",
        "    \"🌸\":\"وردة\",\n",
        "    \"😓\":\"حزن\",\n",
        "    \"💞\":\"حب\",\n",
        "    \"💗\":\"حب\",\n",
        "    \"😑\":\"منزعج\",\n",
        "    \"💭\":\"تفكير\",\n",
        "    \"😎\":\"ثقة\",\n",
        "    \"💛\":\"حب\",\n",
        "    \"😩\":\"حزين\",\n",
        "    \"🥺\":\"حزين\",\n",
        "    \"💪\":\"عضلات\",\n",
        "    \"👍\":\"موافق\",\n",
        "    \"🙏🏻\":\"رجاء طلب\",\n",
        "    \"😳\":\"مصدوم\",\n",
        "    \"👏🏼\":\"تصفيق\",\n",
        "    \"🎶\":\"موسيقي\",\n",
        "    \"🌚\":\"صمت\",\n",
        "    \"💚\":\"حب\",\n",
        "    \"🙏\":\"رجاء طلب\",\n",
        "    \"💘\":\"حب\",\n",
        "    \"🍃\":\"سلام\",\n",
        "    \"☺\":\"يضحك\",\n",
        "    \"🎊\":\"يهنئ\",\n",
        "    \"💥\":\"إنفجار\",\n",
        "    \"😝\":\"يسخر\",\n",
        "    \"💯\":\"تمام\",\n",
        "    \"🐸\":\"ضفدع\",\n",
        "    \"🤦‍♂️\":\"غبي\",\n",
        "    \"🤩\":\"معجب\",\n",
        "    \"🤤\":\"جائع\",\n",
        "    \"😶\":\"مصدوم\",\n",
        "    \"✌️\":\"مرح\",\n",
        "    \"✋🏻\":\"توقف\",\n",
        "    \"😉\":\"غمزة\",\n",
        "    \"🌷\":\"حب\",\n",
        "    \"🙃\":\"مبتسم\",\n",
        "    \"😫\":\"حزين\",\n",
        "    \"😨\":\"مصدوم\",\n",
        "    \"🎼 \":\"موسيقي\",\n",
        "    \"🍁\":\"مرح\",\n",
        "    \"🍂\":\"مرح\",\n",
        "    \"💟\":\"حب\",\n",
        "    \"😪\":\"حزن\",\n",
        "    \"😆\":\"يضحك\",\n",
        "    \"😣\":\"استياء\",\n",
        "    \"☺️\":\"حب\",\n",
        "    \"😱\":\"كارثة\",\n",
        "    \"😁\":\"يضحك\",\n",
        "    \"😖\":\"استياء\",\n",
        "    \"🏃🏼\":\"يجري\",\n",
        "    \"😡\":\"غضب\",\n",
        "    \"🚶\":\"يسير\",\n",
        "    \"🤕\":\"مرض\",\n",
        "    \"🤮\" : \"يتقيئ\",\n",
        "    \"⛔\": \"حذر\",\n",
        "    \"‼️\":\"تعجب\",\n",
        "    \"🕊\":\"طائر\",\n",
        "    \"👌🏻\":\"احسنت\",\n",
        "    \"❣\":\"حب\",\n",
        "    \"🙊\":\"مصدوم\",\n",
        "    \"💃\":\"سعادة مرح\",\n",
        "    \"💃🏼\":\"سعادة مرح\",\n",
        "    \"😜\":\"مرح\",\n",
        "    \"👊\":\"ضربة\",\n",
        "    \"😟\":\"استياء\",\n",
        "    \"💖\":\"حب\",\n",
        "    \"😥\":\"حزن\",\n",
        "    \"🎻\":\"موسيقي\",\n",
        "    \"✒\":\"يكتب\",\n",
        "    \"🚶🏻\":\"يسير\",\n",
        "    \"💎\":\"الماظ\",\n",
        "    \"😷\":\"وباء مرض\",\n",
        "    \"☝\":\"واحد\",\n",
        "    \"🚬\":\"تدخين\",\n",
        "    \"💐\" : \"ورد\",\n",
        "    \"🌻\" : \"ورد\",\n",
        "    \"🌞\" : \"شمس\",\n",
        "    \"👆\" : \"الاول\",\n",
        "    \"⚠️\" :\"تحذير\",\n",
        "    \"🤗\" : \"احتواء\",\n",
        "    \"✖️\": \"غلط\",\n",
        "    \"📍\"  : \"مكان\",\n",
        "    \"👸\" : \"ملكه\",\n",
        "    \"👑\" : \"تاج\",\n",
        "    \"✔️\" : \"صح\",\n",
        "    \"💌\": \"قلب\",\n",
        "    \"😲\" : \"مندهش\",\n",
        "    \"💦\": \"ماء\",\n",
        "    \"🚫\" : \"خطا\",\n",
        "    \"👏🏻\" : \"برافو\",\n",
        "    \"🏊\" :\"يسبح\",\n",
        "    \"👍🏻\": \"تمام\",\n",
        "    \"⭕️\" :\"دائره كبيره\",\n",
        "    \"🎷\" : \"ساكسفون\",\n",
        "    \"👋\": \"تلويح باليد\",\n",
        "    \"✌🏼\": \"علامه النصر\",\n",
        "    \"🌝\":\"مبتسم\",\n",
        "    \"➿\"  : \"عقده مزدوجه\",\n",
        "    \"💪🏼\" : \"قوي\",\n",
        "    \"📩\":  \"تواصل معي\",\n",
        "    \"☕️\": \"قهوه\",\n",
        "    \"😧\" : \"قلق و صدمة\",\n",
        "    \"🗨\": \"رسالة\",\n",
        "    \"❗️\" :\"تعجب\",\n",
        "    \"🙆🏻\": \"اشاره موافقه\",\n",
        "    \"👯\" :\"اخوات\",\n",
        "    \"©\" :  \"رمز\",\n",
        "    \"👵🏽\" :\"سيده عجوزه\",\n",
        "    \"🐣\": \"كتكوت\",\n",
        "    \"🙌\": \"تشجيع\",\n",
        "    \"🙇\": \"شخص ينحني\",\n",
        "    \"👐🏽\":\"ايدي مفتوحه\",\n",
        "    \"👌🏽\": \"بالظبط\",\n",
        "    \"⁉️\" : \"استنكار\",\n",
        "    \"⚽️\": \"كوره\",\n",
        "    \"🕶\" :\"حب\",\n",
        "    \"🎈\" :\"بالون\",\n",
        "    \"🎀\":    \"ورده\",\n",
        "    \"💵\":  \"فلوس\",\n",
        "    \"😋\":  \"جائع\",\n",
        "    \"😛\":  \"يغيظ\",\n",
        "    \"😠\":  \"غاضب\",\n",
        "    \"✍🏻\":  \"يكتب\",\n",
        "    \"🌾\":  \"ارز\",\n",
        "    \"👣\":  \"اثر قدمين\",\n",
        "    \"❌\":\"رفض\",\n",
        "    \"🍟\":\"طعام\",\n",
        "    \"👬\":\"صداقة\",\n",
        "    \"🐰\":\"ارنب\",\n",
        "    \"🦋\" : \"فراشة\",\n",
        "    \"☂\":\"مطر\",\n",
        "    \"⚜\":\"مملكة فرنسا\",\n",
        "    \"🐑\":\"خروف\",\n",
        "    \"🗣\":\"صوت مرتفع\",\n",
        "    \"👌🏼\":\"احسنت\",\n",
        "    \"☘\":\"مرح\",\n",
        "    \"😮\":\"صدمة\",\n",
        "    \"😦\":\"قلق\",\n",
        "    \"⭕\":\"الحق\",\n",
        "    \"✏️\":\"قلم\",\n",
        "    \"ℹ\":\"معلومات\",\n",
        "    \"🙍🏻\":\"رفض\",\n",
        "    \"⚪️\":\"نضارة نقاء\",\n",
        "    \"🐤\":\"حزن\",\n",
        "    \"💫\":\"مرح\",\n",
        "    \"💝\":\"حب\",\n",
        "    \"🍔\":\"طعام\",\n",
        "    \"❤︎\":\"حب\",\n",
        "    \"✈️\":\"سفر\",\n",
        "    \"🏃🏻‍♀️\":\"يسير\",\n",
        "    \"🍳\":\"ذكر\",\n",
        "    \"🎤\":\"مايك غناء\",\n",
        "    \"🎾\":\"كره\",\n",
        "    \"🐔\":\"دجاجة\",\n",
        "    \"🙋\":\"سؤال\",\n",
        "    \"📮\":\"بحر\",\n",
        "    \"💉\":\"دواء\",\n",
        "    \"🙏🏼\":\"رجاء طلب\",\n",
        "    \"💂🏿 \":\"حارس\",\n",
        "    \"🎬\":\"سينما\",\n",
        "    \"♦️\":\"مرح\",\n",
        "    \"💡\":\"قكرة\",\n",
        "    \"‼\":\"تعجب\",\n",
        "    \"👼\":\"طفل\",\n",
        "    \"🔑\":\"مفتاح\",\n",
        "    \"♥️\":\"حب\",\n",
        "    \"🌲\" : \"شجرة\",\n",
        "    \"🌳\" : \"شجرة\",\n",
        "    \"🚩\" : \"حذر\",\n",
        "    \"🚨\" : \"حذر\",\n",
        "    \"🛑\" : \"حذر\",\n",
        "    \"🕋\":\"كعبة\",\n",
        "    \"🐓\":\"دجاجة\",\n",
        "    \"💩\":\"معترض\",\n",
        "    \"👽\":\"فضائي\",\n",
        "    \"☔️\":\"مطر\",\n",
        "    \"🍷\":\"عصير\",\n",
        "    \"🌟\":\"نجمة\",\n",
        "    \"☁️\":\"سحب\",\n",
        "    \"👃\":\"معترض\",\n",
        "    \"🌺\":\"مرح\",\n",
        "    \"🔪\":\"سكينة\",\n",
        "    \"♨\":\"سخونية\",\n",
        "    \"👊🏼\":\"ضرب\",\n",
        "    \"✏\":\"قلم\",\n",
        "    \"🚶🏾‍♀️\":\"يسير\",\n",
        "    \"👊\":\"ضربة\",\n",
        "    \"◾️\":\"وقف\",\n",
        "    \"😚\":\"حب\",\n",
        "    \"🔸\":\"مرح\",\n",
        "    \"👎🏻\":\"لا يعجبني\",\n",
        "    \"👊🏽\":\"ضربة\",\n",
        "    \"😙\":\"حب\",\n",
        "    \"🎥\":\"تصوير\",\n",
        "    \"👉\":\"جذب انتباه\",\n",
        "    \"👏🏽\":\"يصفق\",\n",
        "    \"💪🏻\":\"عضلات\",\n",
        "    \"🏴\":\"اسود\",\n",
        "    \"🔥\":\"حريق\",\n",
        "    \"😬\":\"عدم الراحة\",\n",
        "    \"👊🏿\":\"يضرب\",\n",
        "    \"📚\" : \"كتب\",\n",
        "    \"📌\" : \"علق\",\n",
        "    \"🌿\":\"ورقه شجره\",\n",
        "    \"✋🏼\":\"كف ايد\",\n",
        "    \"👐\":\"ايدي مفتوحه\",\n",
        "    \"☠️\":\"وجه مرعب\",\n",
        "    \"🎉\":\"يهنئ\",\n",
        "    \"🔕\" :\"صامت\",\n",
        "    \"😿\":\"وجه حزين\",\n",
        "    \"☹️\":\"وجه يائس\",\n",
        "    \"😘\" :\"حب\",\n",
        "    \"😰\" :\"خوف و حزن\",\n",
        "    \"🌼\":\"ورده\",\n",
        "    \"💋\": \"بوسه\",\n",
        "    \"👇\":\"لاسفل\",\n",
        "    \"❣️\":\"حب\",\n",
        "    \"🎧\":\"سماعات\",\n",
        "    \"📝\":\"يكتب\",\n",
        "    \"😇\":\"دايخ\",\n",
        "    \"😈\":\"رعب\",\n",
        "    \"🏃\":\"يجري\",\n",
        "    \"✌🏻\":\"علامه النصر\",\n",
        "    \"🔫\":\"يضرب\",\n",
        "    \"❗️\":\"تعجب\",\n",
        "    \"👎\":\"غير موافق\",\n",
        "    \"🔐\":\"قفل\",\n",
        "    \"👈\":\"لليمين\",\n",
        "    \"™\":\"رمز\",\n",
        "    \"🚶🏽\":\"يتمشي\",\n",
        "    \"😯\":\"متفاجأ\",\n",
        "    \"✊\":\"يد مغلقه\",\n",
        "    \"😻\":\"اعجاب\",\n",
        "    \"🙉\" :\"قرد\",\n",
        "    \"👧\":\"طفله صغيره\",\n",
        "    \"🔴\":\"دائره حمراء\",\n",
        "    \"💪🏽\":\"قوه\",\n",
        "    \"💤\":\"ينام\",\n",
        "    \"👀\":\"ينظر\",\n",
        "    \"✍🏻\":\"يكتب\",\n",
        "    \"❄️\":\"تلج\",\n",
        "    \"💀\":\"رعب\",\n",
        "    \"😤\":\"وجه عابس\",\n",
        "    \"🖋\":\"قلم\",\n",
        "    \"🎩\":\"كاب\",\n",
        "    \"☕️\":\"قهوه\",\n",
        "    \"😹\":\"ضحك\",\n",
        "    \"💓\":\"حب\",\n",
        "    \"☄️\":\"نار\",\n",
        "    \"👻\":\"رعب\",\n",
        "    \"✋\": \"يد\",\n",
        "    \"🌱\": \"نبتة\",\n",
        "\n",
        "    # Emoticons\n",
        "    \":)\" : \"يبتسم\",\n",
        "    \"(:\" : \"يبتسم\",\n",
        "    \":(\" : \"حزين\",\n",
        "    \"xD\" : \"يضحك\",\n",
        "    \":=(\": \"يبكي\",\n",
        "    \":'(\": \"حزن\",\n",
        "    \":'‑(\": \"حزن\",\n",
        "    \"XD\" : \"يضحك\",\n",
        "    \":D\" : \"يبتسم\",\n",
        "    \"♬\" : \"موسيقي\",\n",
        "    \"♡\" : \"حب\",\n",
        "    \"☻\"  : \"يبتسم\",\n",
        "}\n",
        "\n",
        "def replace_emojis(text):\n",
        "    pattern = re.compile('|'.join(re.escape(key) for key in emojis.keys()))\n",
        "    replaced_text = pattern.sub(lambda match: emojis[match.group(0)] + ' ', text)\n",
        "    return emoji.replace_emoji(replaced_text, '')\n",
        "\n",
        "data[\"tweet\"] = data[\"tweet\"].apply(lambda document: replace_emojis(document))\n",
        "data.head()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "2Ir8Glj9EEsf"
      },
      "source": [
        "## Removing mentions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "UXgrvqiKEEsg"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>class</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>33372</th>\n",
              "      <td>pos</td>\n",
              "      <td>بخاخ فيجا الالماني انتصاب وتاخير دون تخدير</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41159</th>\n",
              "      <td>pos</td>\n",
              "      <td>شهور و يوم تعال خذ الزرقاء من فريق التماسيح</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18029</th>\n",
              "      <td>neg</td>\n",
              "      <td>حذر  طريق #الدمام × #الخبر ابعدواا عنه</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37264</th>\n",
              "      <td>pos</td>\n",
              "      <td>احلى صباح يضحك</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35690</th>\n",
              "      <td>pos</td>\n",
              "      <td>مع بعض الأصدقاء حب  شاطئ فلامنغو ، أروبا</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      class                                        tweet\n",
              "33372   pos   بخاخ فيجا الالماني انتصاب وتاخير دون تخدير\n",
              "41159   pos  شهور و يوم تعال خذ الزرقاء من فريق التماسيح\n",
              "18029   neg      حذر  طريق #الدمام × #الخبر ابعدواا عنه \n",
              "37264   pos                              احلى صباح يضحك \n",
              "35690   pos     مع بعض الأصدقاء حب  شاطئ فلامنغو ، أروبا"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pattern = r'@[\\w]+'\n",
        "data[\"tweet\"] = data[\"tweet\"].apply(lambda document: re.sub(pattern, ' ', document))\n",
        "data.head()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "AA7faVLeEEsh"
      },
      "source": [
        "## Removing links"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "hm75bZvGEEsh"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>class</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>33372</th>\n",
              "      <td>pos</td>\n",
              "      <td>بخاخ فيجا الالماني انتصاب وتاخير دون تخدير</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41159</th>\n",
              "      <td>pos</td>\n",
              "      <td>شهور و يوم تعال خذ الزرقاء من فريق التماسيح</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18029</th>\n",
              "      <td>neg</td>\n",
              "      <td>حذر  طريق #الدمام × #الخبر ابعدواا عنه</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37264</th>\n",
              "      <td>pos</td>\n",
              "      <td>احلى صباح يضحك</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35690</th>\n",
              "      <td>pos</td>\n",
              "      <td>مع بعض الأصدقاء حب  شاطئ فلامنغو ، أروبا</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      class                                        tweet\n",
              "33372   pos   بخاخ فيجا الالماني انتصاب وتاخير دون تخدير\n",
              "41159   pos  شهور و يوم تعال خذ الزرقاء من فريق التماسيح\n",
              "18029   neg      حذر  طريق #الدمام × #الخبر ابعدواا عنه \n",
              "37264   pos                              احلى صباح يضحك \n",
              "35690   pos     مع بعض الأصدقاء حب  شاطئ فلامنغو ، أروبا"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pattern = r'https?://\\S+'\n",
        "data[\"tweet\"] = data[\"tweet\"].apply(lambda document: re.sub(pattern, ' ', document))\n",
        "data.head()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "_TMg71jAEEsn"
      },
      "source": [
        "## Remove foriegn words"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "hD1EjRxMEEsn"
      },
      "source": [
        "The text includes english, japanese and words for other languages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "HraPS5_SEEso"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>class</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>33372</th>\n",
              "      <td>pos</td>\n",
              "      <td>بخاخ فيجا الالماني انتصاب وتاخير دون تخدير</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41159</th>\n",
              "      <td>pos</td>\n",
              "      <td>شهور و يوم تعال خذ الزرقاء من فريق التماسيح</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18029</th>\n",
              "      <td>neg</td>\n",
              "      <td>حذر  طريق #الدمام × #الخبر ابعدواا عنه</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37264</th>\n",
              "      <td>pos</td>\n",
              "      <td>احلى صباح يضحك</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35690</th>\n",
              "      <td>pos</td>\n",
              "      <td>مع بعض الأصدقاء حب  شاطئ فلامنغو ، أروبا</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      class                                        tweet\n",
              "33372   pos   بخاخ فيجا الالماني انتصاب وتاخير دون تخدير\n",
              "41159   pos  شهور و يوم تعال خذ الزرقاء من فريق التماسيح\n",
              "18029   neg      حذر  طريق #الدمام × #الخبر ابعدواا عنه \n",
              "37264   pos                              احلى صباح يضحك \n",
              "35690   pos     مع بعض الأصدقاء حب  شاطئ فلامنغو ، أروبا"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pattern = r'[a-zA-Z]+'\n",
        "data[\"tweet\"] = data[\"tweet\"].apply(lambda document: re.sub(pattern, ' ', document))\n",
        "data.head()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "_r3f6p9DEEsp"
      },
      "source": [
        "## Remove punctuations & special chars"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "g2gtB69BEEsp"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>class</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>33372</th>\n",
              "      <td>pos</td>\n",
              "      <td>بخاخ فيجا الالماني انتصاب وتاخير دون تخدير</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41159</th>\n",
              "      <td>pos</td>\n",
              "      <td>شهور و يوم تعال خذ الزرقاء من فريق التماسيح</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18029</th>\n",
              "      <td>neg</td>\n",
              "      <td>حذر  طريق  الدمام    الخبر ابعدواا عنه</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37264</th>\n",
              "      <td>pos</td>\n",
              "      <td>احلى صباح يضحك</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35690</th>\n",
              "      <td>pos</td>\n",
              "      <td>مع بعض الأصدقاء حب  شاطئ فلامنغو   أروبا</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      class                                        tweet\n",
              "33372   pos   بخاخ فيجا الالماني انتصاب وتاخير دون تخدير\n",
              "41159   pos  شهور و يوم تعال خذ الزرقاء من فريق التماسيح\n",
              "18029   neg      حذر  طريق  الدمام    الخبر ابعدواا عنه \n",
              "37264   pos                              احلى صباح يضحك \n",
              "35690   pos     مع بعض الأصدقاء حب  شاطئ فلامنغو   أروبا"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pattern = r'[^\\w\\s\\u0600-\\u06FF]+|_|ﷺ|۩|⓵|؟|؛|۞|ﷻ|،| ٰ'\n",
        "data[\"tweet\"] = data[\"tweet\"].apply(lambda document: re.sub(pattern, ' ', document))\n",
        "data.head()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "-BEPhEhYEEsq"
      },
      "source": [
        "## Remove consecutive characters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "pjEAl55ZEEsr"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>class</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>33372</th>\n",
              "      <td>pos</td>\n",
              "      <td>بخاخ فيجا الالماني انتصاب وتاخير دون تخدير</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41159</th>\n",
              "      <td>pos</td>\n",
              "      <td>شهور و يوم تعال خذ الزرقاء من فريق التماسيح</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18029</th>\n",
              "      <td>neg</td>\n",
              "      <td>حذر طريق الدمام الخبر ابعدوا عنه</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37264</th>\n",
              "      <td>pos</td>\n",
              "      <td>احلى صباح يضحك</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35690</th>\n",
              "      <td>pos</td>\n",
              "      <td>مع بعض الأصدقاء حب شاطئ فلامنغو أروبا</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      class                                        tweet\n",
              "33372   pos   بخاخ فيجا الالماني انتصاب وتاخير دون تخدير\n",
              "41159   pos  شهور و يوم تعال خذ الزرقاء من فريق التماسيح\n",
              "18029   neg            حذر طريق الدمام الخبر ابعدوا عنه \n",
              "37264   pos                              احلى صباح يضحك \n",
              "35690   pos        مع بعض الأصدقاء حب شاطئ فلامنغو أروبا"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pattern = r'(.)\\1+'\n",
        "data[\"tweet\"] = data[\"tweet\"].apply(lambda document: re.sub(pattern, r'\\1', document))\n",
        "data.head()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Remove tatweel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "data[\"tweet\"] = data[\"tweet\"].apply(lambda document: araby.strip_tatweel(document))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "MZctqr8qEEsr"
      },
      "source": [
        "## Remove numbers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "xUfiKGlxEEst"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>class</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>33372</th>\n",
              "      <td>pos</td>\n",
              "      <td>بخاخ فيجا الالماني انتصاب وتاخير دون تخدير</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41159</th>\n",
              "      <td>pos</td>\n",
              "      <td>شهور و يوم تعال خذ الزرقاء من فريق التماسيح</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18029</th>\n",
              "      <td>neg</td>\n",
              "      <td>حذر طريق الدمام الخبر ابعدوا عنه</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37264</th>\n",
              "      <td>pos</td>\n",
              "      <td>احلى صباح يضحك</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35690</th>\n",
              "      <td>pos</td>\n",
              "      <td>مع بعض الأصدقاء حب شاطئ فلامنغو أروبا</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      class                                        tweet\n",
              "33372   pos   بخاخ فيجا الالماني انتصاب وتاخير دون تخدير\n",
              "41159   pos  شهور و يوم تعال خذ الزرقاء من فريق التماسيح\n",
              "18029   neg            حذر طريق الدمام الخبر ابعدوا عنه \n",
              "37264   pos                              احلى صباح يضحك \n",
              "35690   pos        مع بعض الأصدقاء حب شاطئ فلامنغو أروبا"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pattern = r'\\d+'\n",
        "data[\"tweet\"] = data[\"tweet\"].apply(lambda document: re.sub(pattern, ' ', document))\n",
        "data.head()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Remove extra whitespaces\n",
        "In this step we get rid of extra whitespaces as well as new lines"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>class</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>33372</th>\n",
              "      <td>pos</td>\n",
              "      <td>بخاخ فيجا الالماني انتصاب وتاخير دون تخدير</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41159</th>\n",
              "      <td>pos</td>\n",
              "      <td>شهور و يوم تعال خذ الزرقاء من فريق التماسيح</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18029</th>\n",
              "      <td>neg</td>\n",
              "      <td>حذر طريق الدمام الخبر ابعدوا عنه</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37264</th>\n",
              "      <td>pos</td>\n",
              "      <td>احلى صباح يضحك</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35690</th>\n",
              "      <td>pos</td>\n",
              "      <td>مع بعض الأصدقاء حب شاطئ فلامنغو أروبا</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      class                                        tweet\n",
              "33372   pos   بخاخ فيجا الالماني انتصاب وتاخير دون تخدير\n",
              "41159   pos  شهور و يوم تعال خذ الزرقاء من فريق التماسيح\n",
              "18029   neg            حذر طريق الدمام الخبر ابعدوا عنه \n",
              "37264   pos                              احلى صباح يضحك \n",
              "35690   pos        مع بعض الأصدقاء حب شاطئ فلامنغو أروبا"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pattern = r'\\s+|\\n+'\n",
        "data[\"tweet\"] = data[\"tweet\"].apply(lambda document: re.sub(pattern, ' ', document))\n",
        "data.head()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Remove harakat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>class</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>33372</th>\n",
              "      <td>pos</td>\n",
              "      <td>بخاخ فيجا الالماني انتصاب وتاخير دون تخدير</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41159</th>\n",
              "      <td>pos</td>\n",
              "      <td>شهور و يوم تعال خذ الزرقاء من فريق التماسيح</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18029</th>\n",
              "      <td>neg</td>\n",
              "      <td>حذر طريق الدمام الخبر ابعدوا عنه</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37264</th>\n",
              "      <td>pos</td>\n",
              "      <td>احلى صباح يضحك</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35690</th>\n",
              "      <td>pos</td>\n",
              "      <td>مع بعض الأصدقاء حب شاطئ فلامنغو أروبا</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      class                                        tweet\n",
              "33372   pos   بخاخ فيجا الالماني انتصاب وتاخير دون تخدير\n",
              "41159   pos  شهور و يوم تعال خذ الزرقاء من فريق التماسيح\n",
              "18029   neg            حذر طريق الدمام الخبر ابعدوا عنه \n",
              "37264   pos                              احلى صباح يضحك \n",
              "35690   pos        مع بعض الأصدقاء حب شاطئ فلامنغو أروبا"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data[\"tweet\"] = data[\"tweet\"].apply(lambda document: araby.strip_tashkeel(document))\n",
        "data.head()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Remove diactrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>class</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>33372</th>\n",
              "      <td>pos</td>\n",
              "      <td>بخاخ فيجا الالماني انتصاب وتاخير دون تخدير</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41159</th>\n",
              "      <td>pos</td>\n",
              "      <td>شهور و يوم تعال خذ الزرقاء من فريق التماسيح</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18029</th>\n",
              "      <td>neg</td>\n",
              "      <td>حذر طريق الدمام الخبر ابعدوا عنه</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37264</th>\n",
              "      <td>pos</td>\n",
              "      <td>احلى صباح يضحك</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35690</th>\n",
              "      <td>pos</td>\n",
              "      <td>مع بعض الأصدقاء حب شاطئ فلامنغو أروبا</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      class                                        tweet\n",
              "33372   pos   بخاخ فيجا الالماني انتصاب وتاخير دون تخدير\n",
              "41159   pos  شهور و يوم تعال خذ الزرقاء من فريق التماسيح\n",
              "18029   neg            حذر طريق الدمام الخبر ابعدوا عنه \n",
              "37264   pos                              احلى صباح يضحك \n",
              "35690   pos        مع بعض الأصدقاء حب شاطئ فلامنغو أروبا"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data[\"tweet\"] = data[\"tweet\"].apply(lambda document: araby.strip_diacritics(document))\n",
        "data.head()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Normalize hamza"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>class</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>33372</th>\n",
              "      <td>pos</td>\n",
              "      <td>بخاخ فيجا الالماني انتصاب وتاخير دون تخدير</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41159</th>\n",
              "      <td>pos</td>\n",
              "      <td>شهور و يوم تعال خذ الزرقاء من فريق التماسيح</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18029</th>\n",
              "      <td>neg</td>\n",
              "      <td>حذر طريق الدمام الخبر ابعدوا عنه</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37264</th>\n",
              "      <td>pos</td>\n",
              "      <td>احلى صباح يضحك</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35690</th>\n",
              "      <td>pos</td>\n",
              "      <td>مع بعض الاصدقاء حب شاطئ فلامنغو اروبا</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      class                                        tweet\n",
              "33372   pos   بخاخ فيجا الالماني انتصاب وتاخير دون تخدير\n",
              "41159   pos  شهور و يوم تعال خذ الزرقاء من فريق التماسيح\n",
              "18029   neg            حذر طريق الدمام الخبر ابعدوا عنه \n",
              "37264   pos                              احلى صباح يضحك \n",
              "35690   pos        مع بعض الاصدقاء حب شاطئ فلامنغو اروبا"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pattern = r\"أ|إ|آ\"\n",
        "data[\"tweet\"] = data[\"tweet\"].apply(lambda document: re.sub(pattern, 'ا', document))\n",
        "data.head()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "8Sy4GggUEEsw"
      },
      "source": [
        "## Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "_Nf_D_MeEEsx"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>class</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>33372</th>\n",
              "      <td>pos</td>\n",
              "      <td>[بخاخ, فيجا, الالماني, انتصاب, وتاخير, دون, تخ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41159</th>\n",
              "      <td>pos</td>\n",
              "      <td>[شهور, و, يوم, تعال, خذ, الزرقاء, من, فريق, ال...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18029</th>\n",
              "      <td>neg</td>\n",
              "      <td>[حذر, طريق, الدمام, الخبر, ابعدوا, عنه]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37264</th>\n",
              "      <td>pos</td>\n",
              "      <td>[احلى, صباح, يضحك]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35690</th>\n",
              "      <td>pos</td>\n",
              "      <td>[مع, بعض, الاصدقاء, حب, شاطئ, فلامنغو, اروبا]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      class                                              tweet\n",
              "33372   pos  [بخاخ, فيجا, الالماني, انتصاب, وتاخير, دون, تخ...\n",
              "41159   pos  [شهور, و, يوم, تعال, خذ, الزرقاء, من, فريق, ال...\n",
              "18029   neg            [حذر, طريق, الدمام, الخبر, ابعدوا, عنه]\n",
              "37264   pos                                 [احلى, صباح, يضحك]\n",
              "35690   pos      [مع, بعض, الاصدقاء, حب, شاطئ, فلامنغو, اروبا]"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data[\"tweet\"] = data[\"tweet\"].apply(lambda document: araby.tokenize(document))\n",
        "data.head()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Remove long & short words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>class</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>33372</th>\n",
              "      <td>pos</td>\n",
              "      <td>[بخاخ, فيجا, الالماني, انتصاب, وتاخير, دون, تخ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41159</th>\n",
              "      <td>pos</td>\n",
              "      <td>[شهور, يوم, تعال, خذ, الزرقاء, من, فريق, التما...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18029</th>\n",
              "      <td>neg</td>\n",
              "      <td>[حذر, طريق, الدمام, الخبر, ابعدوا, عنه]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37264</th>\n",
              "      <td>pos</td>\n",
              "      <td>[احلى, صباح, يضحك]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35690</th>\n",
              "      <td>pos</td>\n",
              "      <td>[مع, بعض, الاصدقاء, حب, شاطئ, فلامنغو, اروبا]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      class                                              tweet\n",
              "33372   pos  [بخاخ, فيجا, الالماني, انتصاب, وتاخير, دون, تخ...\n",
              "41159   pos  [شهور, يوم, تعال, خذ, الزرقاء, من, فريق, التما...\n",
              "18029   neg            [حذر, طريق, الدمام, الخبر, ابعدوا, عنه]\n",
              "37264   pos                                 [احلى, صباح, يضحك]\n",
              "35690   pos      [مع, بعض, الاصدقاء, حب, شاطئ, فلامنغو, اروبا]"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data[\"tweet\"] = data[\"tweet\"].apply(lambda document: [word for word in document if len(word) < 9 and len(word) > 1])\n",
        "data.head()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "pQOiy36-EEsy"
      },
      "source": [
        "## Stemming\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "hFgkKc6GEEsy"
      },
      "outputs": [],
      "source": [
        "ar_stemmer = stemmer(\"arabic\")\n",
        "data[\"tweet\"] = data[\"tweet\"].apply(lambda doc: [ar_stemmer.stemWord(token) for token in doc])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>class</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>33372</th>\n",
              "      <td>pos</td>\n",
              "      <td>[خاخ, فيج, المان, انتصاب, تاخير, دون, تخدير]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41159</th>\n",
              "      <td>pos</td>\n",
              "      <td>[شهور, يوم, تعال, خذ, زرقاء, من, ريق, تماسيح]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18029</th>\n",
              "      <td>neg</td>\n",
              "      <td>[حذر, طريق, دمام, خبر, ابعد, عنه]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37264</th>\n",
              "      <td>pos</td>\n",
              "      <td>[احلي, صباح, يضح]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35690</th>\n",
              "      <td>pos</td>\n",
              "      <td>[مع, بعض, اصدقاء, حب, شاطء, امنغ, اروب]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      class                                          tweet\n",
              "33372   pos   [خاخ, فيج, المان, انتصاب, تاخير, دون, تخدير]\n",
              "41159   pos  [شهور, يوم, تعال, خذ, زرقاء, من, ريق, تماسيح]\n",
              "18029   neg              [حذر, طريق, دمام, خبر, ابعد, عنه]\n",
              "37264   pos                              [احلي, صباح, يضح]\n",
              "35690   pos        [مع, بعض, اصدقاء, حب, شاطء, امنغ, اروب]"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.head()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Removing stop words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "arabic_stopwords = stopwords.words('arabic')\n",
        "arabic_stopwords.extend(stp.stopwords_list())\n",
        "stop_words = {ar_stemmer.stemWord(entry) for entry in arabic_stopwords}\n",
        "with open(\"arabic_stopwords.txt\", \"r\", encoding=\"UTF-8\") as file:\n",
        "    for word in file:\n",
        "        stop_words.add(ar_stemmer.stemWord(word.strip()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "19241"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "open(\"./models/stopwords.pkl\", \"wb\").write(pickle.dumps(stop_words))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>class</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>33372</th>\n",
              "      <td>pos</td>\n",
              "      <td>خاخ فيج المان انتصاب تاخير تخدير</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41159</th>\n",
              "      <td>pos</td>\n",
              "      <td>شهور تعال خذ زرقاء ريق تماسيح</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18029</th>\n",
              "      <td>neg</td>\n",
              "      <td>حذر طريق دمام ابعد</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37264</th>\n",
              "      <td>pos</td>\n",
              "      <td>احلي يضح</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35690</th>\n",
              "      <td>pos</td>\n",
              "      <td>اصدقاء حب شاطء امنغ اروب</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      class                             tweet\n",
              "33372   pos  خاخ فيج المان انتصاب تاخير تخدير\n",
              "41159   pos     شهور تعال خذ زرقاء ريق تماسيح\n",
              "18029   neg                حذر طريق دمام ابعد\n",
              "37264   pos                          احلي يضح\n",
              "35690   pos          اصدقاء حب شاطء امنغ اروب"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def remove_stopwords(document: str) -> str:\n",
        "    words = set(document.split(\" \"))\n",
        "    return \" \".join(list(words - stop_words))\n",
        "\n",
        "data[\"tweet\"] = data[\"tweet\"].apply(lambda document: \" \".join([token for token in document if token not in stop_words]))\n",
        "data.head()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Save preprocessed data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "lw0Z0MsXEEsz"
      },
      "outputs": [],
      "source": [
        "if not os.path.exists(\"preprocessed_data.csv\"):\n",
        "    # remove empty entries\n",
        "    # data.replace('', pd.NA, inplace=True)  # Replace empty strings with NA\n",
        "    # data.dropna(inplace=True)  # Drop rows with NA values\n",
        "    data.to_csv(\"preprocessed_data.csv\") # inspect the resulting file to validate the preprocessing"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "l4AEbbxhEEsz"
      },
      "source": [
        "# Text representation"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Appraisal analysis\n",
        "Bow + G:AO\n",
        "\n",
        "G:AO Appraisal Group by Attitude & Orientation — Total\n",
        "frequency of appraisal groups with each possible combination of Attitude and Orientation, normalized by total number of appraisal groups in the text."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Read lexicon"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'affect_happ_neg': ['حَزِين ', 'قَانِط', 'جَزِع', 'مُحَطَّم ', 'كَئِيب ', 'مُحْبَط', 'مُؤْلِم', 'مُنْقَبِض', 'مُثِير لِلشَّفَقَة', 'مَهْمُوم', 'مُكْتَئِب', 'مُكَدَّر', 'مُمِل', 'بَائِس', 'تَعِيس', 'مُحْزِن', 'قَاتِم', 'مُتَجَهِّم', 'مُنْكَسِر الخَاطِر', 'مُنْعَزِل', 'مُتَدَنِّي', 'مُغْتَم', 'بَكَّاء', 'بَاكٍ', 'دَامع'], 'affect_happ_pos': ['مَرِح', 'نَشِط', 'مُبْتَهِج'], 'affect_inc_neg': ['حَذِر', 'خَائِف', 'مَفْزُوع'], 'affect_satis_neg': ['سَطْحِي', 'مُبْتَذَل', 'مُمِل', 'مُنْزَعِج', 'غَاضِب', 'مَغِيظ', 'مُتَضَايِق', 'سَاخِط', 'سَئِيم'], 'affect_satis_pos': ['مَعْنِي', 'مُنْشَغِل ', 'مُنْهَمِك', 'رَاضٍ', 'مَسْرُور', 'مُعْجَب ', 'سَعِيد', 'مُنْبَهِر', 'مَفْتُون', 'مُثِير', 'مُثِير لِلْإِعْجَاب'], 'affect_sec_neg': ['مُرْتَبِك', 'قَلِق ', 'شَاذّ', 'مُفَاجِئ ', 'مُنْدَهِش', 'مَشْدُوه'], 'affect_sec_pos': ['وَاثِق', 'مُؤَكَّد', 'مُرِيح', 'وَاثِق مِن نَفْسِي', 'مَوْضِع ثِقَة'], 'apprec_comp_balance_neg': ['مُخْتَل', 'مُتَعَارِض', 'مُتَقَطِّع', 'مُتَفَاوِت', 'مَعِيب', 'مُتَنَاقِض', 'فَوْضَوِي', 'مُشَوَّه', 'بَشِع', 'مُحَرَّف'], 'apprec_comp_balance_pos': ['مُتَوَازِن', 'مُتَنَاغِم', 'مُوَحَّد', 'مُتَمَاثِل', 'مُتَنَاسِب', 'مُلَائِم', 'مُحْتَرَم', 'مَنْطِقِي ', 'مُتَنَاسِق', 'رَشِيق', 'مُرَتَّب'], 'apprec_comp_complex_neg': ['مُعَقَّد', 'مُفْرِط', 'بِيزَنْطِي', 'غَامِض', 'مُبْهَم', 'عَكِر ', 'عَادِي', 'اعْتِيَادِي', 'مُبَسَّط'], 'apprec_comp_complex_pos': ['بَسِيط', 'صَافٍ', 'أَنِيق ', 'شَفَّاف', 'وَاضِح', 'دَقِيق ', 'مُرَكَّب', 'غَنِي', 'مُفَصَّل'], 'apprec_reaction_impact_neg': ['بَاهِت', 'مُمِل', 'مُضْجِر ', 'جَاف', 'غَامِض', 'سَقِيم', 'سَطْحِي', 'مُتَوَقَّع', 'رَتِيب', 'خَافِت', 'تَافِه'], 'apprec_reaction_impact_pos': ['لَافِت لِلنَّظَر', 'خَلَّاب', 'جَذَّاب ', 'فَاتِن', 'مُثِير', 'مُؤَثِّر', 'نَشِيط', 'مُذْهِل', 'حَاد', 'رَائِع', 'بَارِز', 'حَسَّاس'], 'apprec_reaction_quality_neg': ['سَيِّئ', 'كَرِيه', 'مُقْرِف ', 'عَادِي', 'قَبِيح', 'بَشِع ', 'بَغِيض', 'غَاضِب', 'مُشْمَئِز'], 'apprec_reaction_quality_pos': ['مَقْبُول', 'رَفِيع', 'جَيِّد', 'مَحْبُوب', 'جَمِيل', 'رَائِع', 'جَذَّاب', 'فَاتِن', 'مُحْتَفِي'], 'apprec_valuation_neg': ['ضَحِل', 'مُخْتَزَل', 'تَافِه', 'ثَانَوِي', 'تَقْلِيدِي', 'رَكِيك', 'مُحَافِظ', 'مُتَأَخِّر', 'قَدِيم', 'شَائِع', 'مُبْتَذَل', 'عَادِي', 'زَائِف', 'كَاذِب', 'مُغْرِي', 'رَخِيص', 'مُزَيَّف', 'غَالِي', 'عَاجِز ', 'عَقِيم', 'بَاطِل'], 'apprec_valuation_pos': ['نَافِذ', 'عَمِيق', 'رَاسِخ', 'مُبْتَكَر', 'أَصِيل', 'خَلَّاق', 'مُنَاسِب', 'مُنْتَظَر', 'مُؤَشِّر', 'مُمَيَّز', 'اسْتِثْنَائِي', 'فَرِيد', 'أَصْلِي', 'حَقِيقِي ', 'نَفِيس', 'ثَمِين', 'مُهِم', 'مُلَائِم', 'مُفِيد', 'فَعَّال'], 'judg_esteem_cap_neg': ['مُتَسَامِح', 'ضَعِيف', 'جَبَان', 'فَاسِد', 'مَرِيض', 'أَعْرَج', 'فَج', 'صِبْيَانِي', 'عَاجِز', 'مُمِل', 'كَئِيب', 'رَهِيب', 'بَطِيء', 'غَبِي', 'ثَقِيل ', 'أَبْلَه', 'عُصَابِي', 'مُخْتَل', 'سَاذَج', 'هَاوٍ', 'أَحْمَق', 'أُمِّي', 'خَشِن', 'جَاهِل ', 'عَاجِز', 'نَاقِص', 'مُخْفِق', 'عَقِيم'], 'judg_esteem_cap_pos': ['قَوِي ', 'حَيَوِي', 'مَتِين ', 'سَلِيم', 'صِحِّي', 'صَالِح ', 'بَالِغ', 'نَاضِج', 'مُجَرَّب ', 'بَارِع', 'هَزْلِي', 'طَرِيف ', 'ثَاقِب', 'ذَكِي', 'مَوْهُوب', 'مُتَوَازِن', 'وَاثِق', 'عَاقِل', 'مَعْقُول', 'خَبِير', 'مَاهِر', 'عَارِف', 'مُهَذَّب', 'مُتَعَلِّم', 'كُفْؤ', 'مُتَمَكِّن ', 'نَاجِح', 'مُنْتِج'], 'judg_esteem_norm_neg': ['مَشْؤُوم', 'بَائِس', 'مَنْحُوس  ', 'غَرِيب', 'عَجِيب', 'مُتَقَلِّب', 'تَائِه', 'غَامِض ', 'مُحَافِظ', 'قَدِيم', 'رِجْعِي', 'مُبْهَم', 'فَاشِل'], 'judg_esteem_norm_pos': ['مَحْظُوظ', 'مُوَفَّق', 'رَائِع', 'عَادِي', 'طَبِيعِي', 'مَأْلُوف ', 'هَادِئ', 'مُسْتَقِر', 'مُتَوَقَّع ', 'رَاهِن', 'عَصْرِي', 'طَلِيعِي', 'مَشْهُور', 'مَغْمُور'], 'judg_esteem_ten_neg': ['خَجُول', 'جَبَان', 'خَوَّاف ', 'مُنْدَفِع', 'بَرِم', 'مُتَهَوِّر', 'مُتَسَرِّع', 'مُتَقَلِّب', 'طَائِش ', 'ضَعِيف', 'غَافِل', 'جَزِع  ', 'خَائِن ', 'مُخَادِع ', 'غَادِر', 'مُتَغَيِّر', 'عَنِيد', 'مُتَعَنِّت', 'مُتَعَمِّد'], 'judg_esteem_ten_pos': ['مِقْدَام', 'شُجَاع', 'بُطُولِي  ', 'حَذِر', 'مُحْتَرِس', 'صَابِر', 'يَقِظ', 'كَامِل', 'دَقِيق', 'نَشِيط', 'مُثَابِر', 'حَازِم', 'مَوْثُوق', 'مُعْتَمَد ', 'مُخْلِص', 'وَفِي', 'ثَابِت', 'مَرِن', 'مُتَكَيِّف ', 'مُتَعَاوِن'], 'judg_sanction_prop_neg': ['سَيِّئ', 'سَافِل', 'شِرِّير ', 'مُرْتَشٍ', 'ظَالِم', 'جَائِر ', 'قَاسٍ', 'خَسِيس', 'شَرِس', 'تَافِه', 'مُتَكَبِّر', 'مُتَغَطْرِس', 'وَقِح', 'فَظ', 'مُحْتَقِر', 'أَنَانِي', 'جَشِع', 'بَخِيل'], 'judg_sanction_prop_pos': ['صَالِح', 'مَعْنَوِي', 'أَخْلَاقِي ', 'مُلْتَزِم بِالقَانُون', 'عَادِل', 'مُنْصِف', 'مُرْهَف', 'لَطِيف', 'حَرِيص  ', 'بَسِيط', 'مُتَوَاضِع', 'وَدِيع  ', 'مُهَذَّب', 'مُحْتَرَم', 'مُوَقَّر', 'إِيثَارِي', 'سَخِي', 'مُحْسِن'], 'judg_sanction_ver_neg': ['غَشَّاش', 'مُخَادِع', 'كَذَّاب ', 'مُضَلِّل', 'مُتَلَاعِب', 'مُرَاوِغ', 'كَلِيل', 'ثَرْثَار'], 'judg_sanction_ver_pos': ['صَادِق', 'نَزِيه', 'مَوْثُوق ', 'صَرِيح', 'وَاضِح', 'مُبَاشِر  ', 'مُحْتَرِس', 'لَبِق'], 'verb_affect_happ_neg': ['كَرِهَ', 'أَبْغَضَ', 'مَقَتَ'], 'verb_affect_happ_pos': ['مَالَ', 'حَبَّ', 'عَشِقَ', 'وَلَعَ'], 'verb_affect_inc_pos': ['افْتَقَدَ', 'اشْتَاقَ', 'تَاقَ']}\n"
          ]
        }
      ],
      "source": [
        "def excel_to_dict(file_path):\n",
        "    workbook = openpyxl.load_workbook(file_path)\n",
        "    data_dict = {}\n",
        "    \n",
        "    for sheet_name in workbook.sheetnames:\n",
        "        sheet = workbook[sheet_name]\n",
        "        values = [cell.value for cell in sheet['A'] if cell.value is not None]\n",
        "        data_dict[sheet_name] = values\n",
        "    \n",
        "    return data_dict\n",
        "\n",
        "# Example usage:\n",
        "lexicon = excel_to_dict(\"./Arabic seed terms.xlsx\")\n",
        "print(lexicon)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Preprocess lexicon"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'affect_happ_neg': ['حزين ', 'قانط', 'جزع', 'محطم ', 'ييب ', 'محبط', 'مولم', 'منقبض', 'مثير للشفق', 'مهموم', 'مكتيب', 'مكدر', 'ممل', 'بايس', 'تعيس', 'محز', 'قاتم', 'متج', 'منكسر الخاطر', 'منعزل', 'متد', 'مغتم', 'كاء', 'باك', 'دامع'], 'affect_happ_pos': ['مرح', 'نشط', 'مبتهج'], 'affect_inc_neg': ['حذر', 'خايف', 'مفزوع'], 'affect_satis_neg': ['سطح', 'مبتذل', 'ممل', 'منزعج', 'غاضب', 'مغيظ', 'متضايق', 'ساخط', 'سييم'], 'affect_satis_pos': ['معن', 'منشغل ', 'منهم', 'راض', 'مسرور', 'معجب ', 'سعيد', 'منبهر', 'مفتون', 'مثير', 'مثير للاعجاب'], 'affect_sec_neg': ['مرتب', 'قلق ', 'شاذ', 'مفاجي ', 'مندهش', 'مشد'], 'affect_sec_pos': ['واثق', 'موكد', 'مريح', 'واثق من نفس', 'موضع ثق'], 'apprec_comp_balance_neg': ['مختل', 'متعارض', 'متقطع', 'متفاو', 'معيب', 'متناقض', 'وضو', 'مشو', 'بشع', 'محرف'], 'apprec_comp_balance_pos': ['متواز', 'متناغم', 'موحد', 'متماثل', 'متناسب', 'ملايم', 'محترم', 'منطقي ', 'متناسق', 'رشيق', 'مرتب'], 'apprec_comp_complex_neg': ['معقد', 'مفرط', 'يزنط', 'غامض', 'مبهم', 'عكر ', 'عاد', 'اعتياد', 'مبسط'], 'apprec_comp_complex_pos': ['سيط', 'صاف', 'انيق ', 'شفاف', 'واضح', 'دقيق ', 'مركب', 'غن', 'مفصل'], 'apprec_reaction_impact_neg': ['باه', 'ممل', 'مضجر ', 'جاف', 'غامض', 'سقيم', 'سطح', 'متوقع', 'رتيب', 'خاف', 'تاف'], 'apprec_reaction_impact_pos': ['افت للنظر', 'خلاب', 'جذاب ', 'فاتن', 'مثير', 'موثر', 'نشيط', 'مذهل', 'حاد', 'رايع', 'بارز', 'حساس'], 'apprec_reaction_quality_neg': ['سيء', 'كري', 'مقرف ', 'عاد', 'قبيح', 'شع ', 'غيض', 'غاضب', 'مشميز'], 'apprec_reaction_quality_pos': ['مقبول', 'رفيع', 'جيد', 'محبوب', 'جميل', 'رايع', 'جذاب', 'فاتن', 'محتف'], 'apprec_valuation_neg': ['ضحل', 'مختزل', 'تاف', 'ثانو', 'تقليد', 'ركي', 'محافظ', 'متاخر', 'قديم', 'شايع', 'مبتذل', 'عاد', 'زايف', 'كاذب', 'مغر', 'رخيص', 'مزيف', 'غال', 'عاجز ', 'عقيم', 'باطل'], 'apprec_valuation_pos': ['نافذ', 'عميق', 'راسخ', 'مبتكر', 'اصيل', 'خلاق', 'مناسب', 'منتظر', 'موشر', 'مميز', 'استثناء', 'ريد', 'اصل', 'حقيقي ', 'نفيس', 'ثمين', 'مهم', 'ملايم', 'مفيد', 'عال'], 'judg_esteem_cap_neg': ['متسامح', 'ضعيف', 'جبان', 'فاسد', 'مريض', 'اعرج', 'فج', 'صبي', 'عاجز', 'ممل', 'كييب', 'رهيب', 'طيء', 'غب', 'ثقيل ', 'ابل', 'عصاب', 'مختل', 'ساذج', 'هاو', 'احمق', 'ام', 'خشن', 'جاهل ', 'عاجز', 'ناقص', 'مخفق', 'عقيم'], 'judg_esteem_cap_pos': ['قوي ', 'حيو', 'متين ', 'سليم', 'صح', 'صالح ', 'بالغ', 'ناضج', 'مجرب ', 'بارع', 'هزل', 'طريف ', 'ثاقب', 'ذك', 'موهوب', 'متواز', 'واثق', 'عاقل', 'معقول', 'خبير', 'ماهر', 'عارف', 'مهذب', 'متعلم', 'كفء', 'متمكن ', 'ناجح', 'منتج'], 'judg_esteem_norm_neg': ['مشووم', 'بايس', 'منحوس  ', 'غريب', 'عجيب', 'متقلب', 'تاء', 'غامض ', 'محافظ', 'قديم', 'رجع', 'مبهم', 'فاشل'], 'judg_esteem_norm_pos': ['محظوظ', 'موفق', 'رايع', 'عاد', 'طبيع', 'مالوف ', 'هادء', 'مستقر', 'متوقع ', 'راه', 'عصر', 'طليع', 'مشهور', 'مغمور'], 'judg_esteem_ten_neg': ['خجول', 'جبان', 'خواف ', 'مندفع', 'برم', 'متهور', 'متسرع', 'متقلب', 'طايش ', 'ضعيف', 'غافل', 'جزع  ', 'خاين ', 'مخادع ', 'غادر', 'متغير', 'عنيد', 'متعن', 'متعمد'], 'judg_esteem_ten_pos': ['مقدام', 'شجاع', 'طولي  ', 'حذر', 'محترس', 'صابر', 'يقظ', 'كامل', 'دقيق', 'نشيط', 'مثابر', 'حازم', 'موثوق', 'معتمد ', 'مخلص', 'وف', 'ثاب', 'مرن', 'متكيف ', 'متعا'], 'judg_sanction_prop_neg': ['سيء', 'سافل', 'شرير ', 'مرتش', 'ظالم', 'جاير ', 'قاس', 'خسيس', 'شرس', 'تاف', 'متكبر', 'متغطرس', 'وقح', 'فظ', 'محتقر', 'انا', 'جشع', 'خيل'], 'judg_sanction_prop_pos': ['صالح', 'معنو', 'اخلاقي ', 'ملتزم بالقان', 'عادل', 'منصف', 'مرهف', 'لطيف', 'حريص  ', 'سيط', 'متواضع', 'ديع  ', 'مهذب', 'محترم', 'موقر', 'ايثار', 'سخ', 'محس'], 'judg_sanction_ver_neg': ['غشاش', 'مخادع', 'ذاب ', 'مضلل', 'متلاعب', 'مراوغ', 'كليل', 'ثرثار'], 'judg_sanction_ver_pos': ['صادق', 'نزي', 'موثوق ', 'صريح', 'واضح', 'مباشر  ', 'محترس', 'لبق'], 'verb_affect_happ_neg': ['كره', 'ابغض', 'مقت'], 'verb_affect_happ_pos': ['مال', 'حب', 'عشق', 'ولع'], 'verb_affect_inc_pos': ['افتقد', 'اشتاق', 'تاق']}\n"
          ]
        }
      ],
      "source": [
        "ar_stemmer = stemmer(\"arabic\")\n",
        "for key, val in lexicon.items():\n",
        "    for idx, val in enumerate(val):\n",
        "        preprocessed_val = araby.strip_tashkeel(val)\n",
        "        preprocessed_val = araby.strip_diacritics(preprocessed_val)\n",
        "        preprocessed_val = re.sub(r\"أ|إ|آ\", 'ا', preprocessed_val)\n",
        "        preprocessed_val = ar_stemmer.stemWord(preprocessed_val)\n",
        "        lexicon[key][idx] = preprocessed_val\n",
        "print(lexicon)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Appraisal features"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Construct a word to appraisal group mapping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'حزين ': 'affect_happ_neg',\n",
              " 'قانط': 'affect_happ_neg',\n",
              " 'جزع': 'affect_happ_neg',\n",
              " 'محطم ': 'affect_happ_neg',\n",
              " 'ييب ': 'affect_happ_neg',\n",
              " 'محبط': 'affect_happ_neg',\n",
              " 'مولم': 'affect_happ_neg',\n",
              " 'منقبض': 'affect_happ_neg',\n",
              " 'مثير للشفق': 'affect_happ_neg',\n",
              " 'مهموم': 'affect_happ_neg',\n",
              " 'مكتيب': 'affect_happ_neg',\n",
              " 'مكدر': 'affect_happ_neg',\n",
              " 'ممل': 'judg_esteem_cap_neg',\n",
              " 'بايس': 'judg_esteem_norm_neg',\n",
              " 'تعيس': 'affect_happ_neg',\n",
              " 'محز': 'affect_happ_neg',\n",
              " 'قاتم': 'affect_happ_neg',\n",
              " 'متج': 'affect_happ_neg',\n",
              " 'منكسر الخاطر': 'affect_happ_neg',\n",
              " 'منعزل': 'affect_happ_neg',\n",
              " 'متد': 'affect_happ_neg',\n",
              " 'مغتم': 'affect_happ_neg',\n",
              " 'كاء': 'affect_happ_neg',\n",
              " 'باك': 'affect_happ_neg',\n",
              " 'دامع': 'affect_happ_neg',\n",
              " 'مرح': 'affect_happ_pos',\n",
              " 'نشط': 'affect_happ_pos',\n",
              " 'مبتهج': 'affect_happ_pos',\n",
              " 'حذر': 'judg_esteem_ten_pos',\n",
              " 'خايف': 'affect_inc_neg',\n",
              " 'مفزوع': 'affect_inc_neg',\n",
              " 'سطح': 'apprec_reaction_impact_neg',\n",
              " 'مبتذل': 'apprec_valuation_neg',\n",
              " 'منزعج': 'affect_satis_neg',\n",
              " 'غاضب': 'apprec_reaction_quality_neg',\n",
              " 'مغيظ': 'affect_satis_neg',\n",
              " 'متضايق': 'affect_satis_neg',\n",
              " 'ساخط': 'affect_satis_neg',\n",
              " 'سييم': 'affect_satis_neg',\n",
              " 'معن': 'affect_satis_pos',\n",
              " 'منشغل ': 'affect_satis_pos',\n",
              " 'منهم': 'affect_satis_pos',\n",
              " 'راض': 'affect_satis_pos',\n",
              " 'مسرور': 'affect_satis_pos',\n",
              " 'معجب ': 'affect_satis_pos',\n",
              " 'سعيد': 'affect_satis_pos',\n",
              " 'منبهر': 'affect_satis_pos',\n",
              " 'مفتون': 'affect_satis_pos',\n",
              " 'مثير': 'apprec_reaction_impact_pos',\n",
              " 'مثير للاعجاب': 'affect_satis_pos',\n",
              " 'مرتب': 'apprec_comp_balance_pos',\n",
              " 'قلق ': 'affect_sec_neg',\n",
              " 'شاذ': 'affect_sec_neg',\n",
              " 'مفاجي ': 'affect_sec_neg',\n",
              " 'مندهش': 'affect_sec_neg',\n",
              " 'مشد': 'affect_sec_neg',\n",
              " 'واثق': 'judg_esteem_cap_pos',\n",
              " 'موكد': 'affect_sec_pos',\n",
              " 'مريح': 'affect_sec_pos',\n",
              " 'واثق من نفس': 'affect_sec_pos',\n",
              " 'موضع ثق': 'affect_sec_pos',\n",
              " 'مختل': 'judg_esteem_cap_neg',\n",
              " 'متعارض': 'apprec_comp_balance_neg',\n",
              " 'متقطع': 'apprec_comp_balance_neg',\n",
              " 'متفاو': 'apprec_comp_balance_neg',\n",
              " 'معيب': 'apprec_comp_balance_neg',\n",
              " 'متناقض': 'apprec_comp_balance_neg',\n",
              " 'وضو': 'apprec_comp_balance_neg',\n",
              " 'مشو': 'apprec_comp_balance_neg',\n",
              " 'بشع': 'apprec_comp_balance_neg',\n",
              " 'محرف': 'apprec_comp_balance_neg',\n",
              " 'متواز': 'judg_esteem_cap_pos',\n",
              " 'متناغم': 'apprec_comp_balance_pos',\n",
              " 'موحد': 'apprec_comp_balance_pos',\n",
              " 'متماثل': 'apprec_comp_balance_pos',\n",
              " 'متناسب': 'apprec_comp_balance_pos',\n",
              " 'ملايم': 'apprec_valuation_pos',\n",
              " 'محترم': 'judg_sanction_prop_pos',\n",
              " 'منطقي ': 'apprec_comp_balance_pos',\n",
              " 'متناسق': 'apprec_comp_balance_pos',\n",
              " 'رشيق': 'apprec_comp_balance_pos',\n",
              " 'معقد': 'apprec_comp_complex_neg',\n",
              " 'مفرط': 'apprec_comp_complex_neg',\n",
              " 'يزنط': 'apprec_comp_complex_neg',\n",
              " 'غامض': 'apprec_reaction_impact_neg',\n",
              " 'مبهم': 'judg_esteem_norm_neg',\n",
              " 'عكر ': 'apprec_comp_complex_neg',\n",
              " 'عاد': 'judg_esteem_norm_pos',\n",
              " 'اعتياد': 'apprec_comp_complex_neg',\n",
              " 'مبسط': 'apprec_comp_complex_neg',\n",
              " 'سيط': 'judg_sanction_prop_pos',\n",
              " 'صاف': 'apprec_comp_complex_pos',\n",
              " 'انيق ': 'apprec_comp_complex_pos',\n",
              " 'شفاف': 'apprec_comp_complex_pos',\n",
              " 'واضح': 'judg_sanction_ver_pos',\n",
              " 'دقيق ': 'apprec_comp_complex_pos',\n",
              " 'مركب': 'apprec_comp_complex_pos',\n",
              " 'غن': 'apprec_comp_complex_pos',\n",
              " 'مفصل': 'apprec_comp_complex_pos',\n",
              " 'باه': 'apprec_reaction_impact_neg',\n",
              " 'مضجر ': 'apprec_reaction_impact_neg',\n",
              " 'جاف': 'apprec_reaction_impact_neg',\n",
              " 'سقيم': 'apprec_reaction_impact_neg',\n",
              " 'متوقع': 'apprec_reaction_impact_neg',\n",
              " 'رتيب': 'apprec_reaction_impact_neg',\n",
              " 'خاف': 'apprec_reaction_impact_neg',\n",
              " 'تاف': 'judg_sanction_prop_neg',\n",
              " 'افت للنظر': 'apprec_reaction_impact_pos',\n",
              " 'خلاب': 'apprec_reaction_impact_pos',\n",
              " 'جذاب ': 'apprec_reaction_impact_pos',\n",
              " 'فاتن': 'apprec_reaction_quality_pos',\n",
              " 'موثر': 'apprec_reaction_impact_pos',\n",
              " 'نشيط': 'judg_esteem_ten_pos',\n",
              " 'مذهل': 'apprec_reaction_impact_pos',\n",
              " 'حاد': 'apprec_reaction_impact_pos',\n",
              " 'رايع': 'judg_esteem_norm_pos',\n",
              " 'بارز': 'apprec_reaction_impact_pos',\n",
              " 'حساس': 'apprec_reaction_impact_pos',\n",
              " 'سيء': 'judg_sanction_prop_neg',\n",
              " 'كري': 'apprec_reaction_quality_neg',\n",
              " 'مقرف ': 'apprec_reaction_quality_neg',\n",
              " 'قبيح': 'apprec_reaction_quality_neg',\n",
              " 'شع ': 'apprec_reaction_quality_neg',\n",
              " 'غيض': 'apprec_reaction_quality_neg',\n",
              " 'مشميز': 'apprec_reaction_quality_neg',\n",
              " 'مقبول': 'apprec_reaction_quality_pos',\n",
              " 'رفيع': 'apprec_reaction_quality_pos',\n",
              " 'جيد': 'apprec_reaction_quality_pos',\n",
              " 'محبوب': 'apprec_reaction_quality_pos',\n",
              " 'جميل': 'apprec_reaction_quality_pos',\n",
              " 'جذاب': 'apprec_reaction_quality_pos',\n",
              " 'محتف': 'apprec_reaction_quality_pos',\n",
              " 'ضحل': 'apprec_valuation_neg',\n",
              " 'مختزل': 'apprec_valuation_neg',\n",
              " 'ثانو': 'apprec_valuation_neg',\n",
              " 'تقليد': 'apprec_valuation_neg',\n",
              " 'ركي': 'apprec_valuation_neg',\n",
              " 'محافظ': 'judg_esteem_norm_neg',\n",
              " 'متاخر': 'apprec_valuation_neg',\n",
              " 'قديم': 'judg_esteem_norm_neg',\n",
              " 'شايع': 'apprec_valuation_neg',\n",
              " 'زايف': 'apprec_valuation_neg',\n",
              " 'كاذب': 'apprec_valuation_neg',\n",
              " 'مغر': 'apprec_valuation_neg',\n",
              " 'رخيص': 'apprec_valuation_neg',\n",
              " 'مزيف': 'apprec_valuation_neg',\n",
              " 'غال': 'apprec_valuation_neg',\n",
              " 'عاجز ': 'apprec_valuation_neg',\n",
              " 'عقيم': 'judg_esteem_cap_neg',\n",
              " 'باطل': 'apprec_valuation_neg',\n",
              " 'نافذ': 'apprec_valuation_pos',\n",
              " 'عميق': 'apprec_valuation_pos',\n",
              " 'راسخ': 'apprec_valuation_pos',\n",
              " 'مبتكر': 'apprec_valuation_pos',\n",
              " 'اصيل': 'apprec_valuation_pos',\n",
              " 'خلاق': 'apprec_valuation_pos',\n",
              " 'مناسب': 'apprec_valuation_pos',\n",
              " 'منتظر': 'apprec_valuation_pos',\n",
              " 'موشر': 'apprec_valuation_pos',\n",
              " 'مميز': 'apprec_valuation_pos',\n",
              " 'استثناء': 'apprec_valuation_pos',\n",
              " 'ريد': 'apprec_valuation_pos',\n",
              " 'اصل': 'apprec_valuation_pos',\n",
              " 'حقيقي ': 'apprec_valuation_pos',\n",
              " 'نفيس': 'apprec_valuation_pos',\n",
              " 'ثمين': 'apprec_valuation_pos',\n",
              " 'مهم': 'apprec_valuation_pos',\n",
              " 'مفيد': 'apprec_valuation_pos',\n",
              " 'عال': 'apprec_valuation_pos',\n",
              " 'متسامح': 'judg_esteem_cap_neg',\n",
              " 'ضعيف': 'judg_esteem_ten_neg',\n",
              " 'جبان': 'judg_esteem_ten_neg',\n",
              " 'فاسد': 'judg_esteem_cap_neg',\n",
              " 'مريض': 'judg_esteem_cap_neg',\n",
              " 'اعرج': 'judg_esteem_cap_neg',\n",
              " 'فج': 'judg_esteem_cap_neg',\n",
              " 'صبي': 'judg_esteem_cap_neg',\n",
              " 'عاجز': 'judg_esteem_cap_neg',\n",
              " 'كييب': 'judg_esteem_cap_neg',\n",
              " 'رهيب': 'judg_esteem_cap_neg',\n",
              " 'طيء': 'judg_esteem_cap_neg',\n",
              " 'غب': 'judg_esteem_cap_neg',\n",
              " 'ثقيل ': 'judg_esteem_cap_neg',\n",
              " 'ابل': 'judg_esteem_cap_neg',\n",
              " 'عصاب': 'judg_esteem_cap_neg',\n",
              " 'ساذج': 'judg_esteem_cap_neg',\n",
              " 'هاو': 'judg_esteem_cap_neg',\n",
              " 'احمق': 'judg_esteem_cap_neg',\n",
              " 'ام': 'judg_esteem_cap_neg',\n",
              " 'خشن': 'judg_esteem_cap_neg',\n",
              " 'جاهل ': 'judg_esteem_cap_neg',\n",
              " 'ناقص': 'judg_esteem_cap_neg',\n",
              " 'مخفق': 'judg_esteem_cap_neg',\n",
              " 'قوي ': 'judg_esteem_cap_pos',\n",
              " 'حيو': 'judg_esteem_cap_pos',\n",
              " 'متين ': 'judg_esteem_cap_pos',\n",
              " 'سليم': 'judg_esteem_cap_pos',\n",
              " 'صح': 'judg_esteem_cap_pos',\n",
              " 'صالح ': 'judg_esteem_cap_pos',\n",
              " 'بالغ': 'judg_esteem_cap_pos',\n",
              " 'ناضج': 'judg_esteem_cap_pos',\n",
              " 'مجرب ': 'judg_esteem_cap_pos',\n",
              " 'بارع': 'judg_esteem_cap_pos',\n",
              " 'هزل': 'judg_esteem_cap_pos',\n",
              " 'طريف ': 'judg_esteem_cap_pos',\n",
              " 'ثاقب': 'judg_esteem_cap_pos',\n",
              " 'ذك': 'judg_esteem_cap_pos',\n",
              " 'موهوب': 'judg_esteem_cap_pos',\n",
              " 'عاقل': 'judg_esteem_cap_pos',\n",
              " 'معقول': 'judg_esteem_cap_pos',\n",
              " 'خبير': 'judg_esteem_cap_pos',\n",
              " 'ماهر': 'judg_esteem_cap_pos',\n",
              " 'عارف': 'judg_esteem_cap_pos',\n",
              " 'مهذب': 'judg_sanction_prop_pos',\n",
              " 'متعلم': 'judg_esteem_cap_pos',\n",
              " 'كفء': 'judg_esteem_cap_pos',\n",
              " 'متمكن ': 'judg_esteem_cap_pos',\n",
              " 'ناجح': 'judg_esteem_cap_pos',\n",
              " 'منتج': 'judg_esteem_cap_pos',\n",
              " 'مشووم': 'judg_esteem_norm_neg',\n",
              " 'منحوس  ': 'judg_esteem_norm_neg',\n",
              " 'غريب': 'judg_esteem_norm_neg',\n",
              " 'عجيب': 'judg_esteem_norm_neg',\n",
              " 'متقلب': 'judg_esteem_ten_neg',\n",
              " 'تاء': 'judg_esteem_norm_neg',\n",
              " 'غامض ': 'judg_esteem_norm_neg',\n",
              " 'رجع': 'judg_esteem_norm_neg',\n",
              " 'فاشل': 'judg_esteem_norm_neg',\n",
              " 'محظوظ': 'judg_esteem_norm_pos',\n",
              " 'موفق': 'judg_esteem_norm_pos',\n",
              " 'طبيع': 'judg_esteem_norm_pos',\n",
              " 'مالوف ': 'judg_esteem_norm_pos',\n",
              " 'هادء': 'judg_esteem_norm_pos',\n",
              " 'مستقر': 'judg_esteem_norm_pos',\n",
              " 'متوقع ': 'judg_esteem_norm_pos',\n",
              " 'راه': 'judg_esteem_norm_pos',\n",
              " 'عصر': 'judg_esteem_norm_pos',\n",
              " 'طليع': 'judg_esteem_norm_pos',\n",
              " 'مشهور': 'judg_esteem_norm_pos',\n",
              " 'مغمور': 'judg_esteem_norm_pos',\n",
              " 'خجول': 'judg_esteem_ten_neg',\n",
              " 'خواف ': 'judg_esteem_ten_neg',\n",
              " 'مندفع': 'judg_esteem_ten_neg',\n",
              " 'برم': 'judg_esteem_ten_neg',\n",
              " 'متهور': 'judg_esteem_ten_neg',\n",
              " 'متسرع': 'judg_esteem_ten_neg',\n",
              " 'طايش ': 'judg_esteem_ten_neg',\n",
              " 'غافل': 'judg_esteem_ten_neg',\n",
              " 'جزع  ': 'judg_esteem_ten_neg',\n",
              " 'خاين ': 'judg_esteem_ten_neg',\n",
              " 'مخادع ': 'judg_esteem_ten_neg',\n",
              " 'غادر': 'judg_esteem_ten_neg',\n",
              " 'متغير': 'judg_esteem_ten_neg',\n",
              " 'عنيد': 'judg_esteem_ten_neg',\n",
              " 'متعن': 'judg_esteem_ten_neg',\n",
              " 'متعمد': 'judg_esteem_ten_neg',\n",
              " 'مقدام': 'judg_esteem_ten_pos',\n",
              " 'شجاع': 'judg_esteem_ten_pos',\n",
              " 'طولي  ': 'judg_esteem_ten_pos',\n",
              " 'محترس': 'judg_sanction_ver_pos',\n",
              " 'صابر': 'judg_esteem_ten_pos',\n",
              " 'يقظ': 'judg_esteem_ten_pos',\n",
              " 'كامل': 'judg_esteem_ten_pos',\n",
              " 'دقيق': 'judg_esteem_ten_pos',\n",
              " 'مثابر': 'judg_esteem_ten_pos',\n",
              " 'حازم': 'judg_esteem_ten_pos',\n",
              " 'موثوق': 'judg_esteem_ten_pos',\n",
              " 'معتمد ': 'judg_esteem_ten_pos',\n",
              " 'مخلص': 'judg_esteem_ten_pos',\n",
              " 'وف': 'judg_esteem_ten_pos',\n",
              " 'ثاب': 'judg_esteem_ten_pos',\n",
              " 'مرن': 'judg_esteem_ten_pos',\n",
              " 'متكيف ': 'judg_esteem_ten_pos',\n",
              " 'متعا': 'judg_esteem_ten_pos',\n",
              " 'سافل': 'judg_sanction_prop_neg',\n",
              " 'شرير ': 'judg_sanction_prop_neg',\n",
              " 'مرتش': 'judg_sanction_prop_neg',\n",
              " 'ظالم': 'judg_sanction_prop_neg',\n",
              " 'جاير ': 'judg_sanction_prop_neg',\n",
              " 'قاس': 'judg_sanction_prop_neg',\n",
              " 'خسيس': 'judg_sanction_prop_neg',\n",
              " 'شرس': 'judg_sanction_prop_neg',\n",
              " 'متكبر': 'judg_sanction_prop_neg',\n",
              " 'متغطرس': 'judg_sanction_prop_neg',\n",
              " 'وقح': 'judg_sanction_prop_neg',\n",
              " 'فظ': 'judg_sanction_prop_neg',\n",
              " 'محتقر': 'judg_sanction_prop_neg',\n",
              " 'انا': 'judg_sanction_prop_neg',\n",
              " 'جشع': 'judg_sanction_prop_neg',\n",
              " 'خيل': 'judg_sanction_prop_neg',\n",
              " 'صالح': 'judg_sanction_prop_pos',\n",
              " 'معنو': 'judg_sanction_prop_pos',\n",
              " 'اخلاقي ': 'judg_sanction_prop_pos',\n",
              " 'ملتزم بالقان': 'judg_sanction_prop_pos',\n",
              " 'عادل': 'judg_sanction_prop_pos',\n",
              " 'منصف': 'judg_sanction_prop_pos',\n",
              " 'مرهف': 'judg_sanction_prop_pos',\n",
              " 'لطيف': 'judg_sanction_prop_pos',\n",
              " 'حريص  ': 'judg_sanction_prop_pos',\n",
              " 'متواضع': 'judg_sanction_prop_pos',\n",
              " 'ديع  ': 'judg_sanction_prop_pos',\n",
              " 'موقر': 'judg_sanction_prop_pos',\n",
              " 'ايثار': 'judg_sanction_prop_pos',\n",
              " 'سخ': 'judg_sanction_prop_pos',\n",
              " 'محس': 'judg_sanction_prop_pos',\n",
              " 'غشاش': 'judg_sanction_ver_neg',\n",
              " 'مخادع': 'judg_sanction_ver_neg',\n",
              " 'ذاب ': 'judg_sanction_ver_neg',\n",
              " 'مضلل': 'judg_sanction_ver_neg',\n",
              " 'متلاعب': 'judg_sanction_ver_neg',\n",
              " 'مراوغ': 'judg_sanction_ver_neg',\n",
              " 'كليل': 'judg_sanction_ver_neg',\n",
              " 'ثرثار': 'judg_sanction_ver_neg',\n",
              " 'صادق': 'judg_sanction_ver_pos',\n",
              " 'نزي': 'judg_sanction_ver_pos',\n",
              " 'موثوق ': 'judg_sanction_ver_pos',\n",
              " 'صريح': 'judg_sanction_ver_pos',\n",
              " 'مباشر  ': 'judg_sanction_ver_pos',\n",
              " 'لبق': 'judg_sanction_ver_pos',\n",
              " 'كره': 'verb_affect_happ_neg',\n",
              " 'ابغض': 'verb_affect_happ_neg',\n",
              " 'مقت': 'verb_affect_happ_neg',\n",
              " 'مال': 'verb_affect_happ_pos',\n",
              " 'حب': 'verb_affect_happ_pos',\n",
              " 'عشق': 'verb_affect_happ_pos',\n",
              " 'ولع': 'verb_affect_happ_pos',\n",
              " 'افتقد': 'verb_affect_inc_pos',\n",
              " 'اشتاق': 'verb_affect_inc_pos',\n",
              " 'تاق': 'verb_affect_inc_pos'}"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "word_to_appraisal_grp = {}\n",
        "for key, val in lexicon.items():\n",
        "    for values in val:\n",
        "        word_to_appraisal_grp[values] = key\n",
        "word_to_appraisal_grp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'affect_happ_neg': 0,\n",
              " 'affect_happ_pos': 1,\n",
              " 'affect_inc_neg': 2,\n",
              " 'affect_satis_neg': 3,\n",
              " 'affect_satis_pos': 4,\n",
              " 'affect_sec_neg': 5,\n",
              " 'affect_sec_pos': 6,\n",
              " 'apprec_comp_balance_neg': 7,\n",
              " 'apprec_comp_balance_pos': 8,\n",
              " 'apprec_comp_complex_neg': 9,\n",
              " 'apprec_comp_complex_pos': 10,\n",
              " 'apprec_reaction_impact_neg': 11,\n",
              " 'apprec_reaction_impact_pos': 12,\n",
              " 'apprec_reaction_quality_neg': 13,\n",
              " 'apprec_reaction_quality_pos': 14,\n",
              " 'apprec_valuation_neg': 15,\n",
              " 'apprec_valuation_pos': 16,\n",
              " 'judg_esteem_cap_neg': 17,\n",
              " 'judg_esteem_cap_pos': 18,\n",
              " 'judg_esteem_norm_neg': 19,\n",
              " 'judg_esteem_norm_pos': 20,\n",
              " 'judg_esteem_ten_neg': 21,\n",
              " 'judg_esteem_ten_pos': 22,\n",
              " 'judg_sanction_prop_neg': 23,\n",
              " 'judg_sanction_prop_pos': 24,\n",
              " 'judg_sanction_ver_neg': 25,\n",
              " 'judg_sanction_ver_pos': 26,\n",
              " 'verb_affect_happ_neg': 27,\n",
              " 'verb_affect_happ_pos': 28,\n",
              " 'verb_affect_inc_pos': 29}"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "appraisal_grp_to_idx = {}\n",
        "idx = 0\n",
        "for appraisal_grp in list(lexicon.keys()):\n",
        "    appraisal_grp_to_idx[appraisal_grp] = idx\n",
        "    idx += 1\n",
        "appraisal_grp_to_idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "def appraisal_features(document: str) -> List[float]:\n",
        "    res = np.zeros(len(lexicon))\n",
        "    tokens = [word for word in document.split(\" \")]\n",
        "    count_appraisal_grps = 0\n",
        "    for token in tokens:\n",
        "        if token in word_to_appraisal_grp:\n",
        "            res[ appraisal_grp_to_idx[word_to_appraisal_grp[token]] ] += 1\n",
        "            count_appraisal_grps += 1\n",
        "    # normalize features by the count of appraisal groups if the count != 0\n",
        "    res = res / count_appraisal_grps if count_appraisal_grps != 0 else res\n",
        "    return res\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Split data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(24742,)"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(data[\"tweet\"], data[\"class\"], test_size = 0.2, random_state = SEED, stratify = data[\"class\"])\n",
        "vectorizer = CountVectorizer()\n",
        "\n",
        "X_train_BOW = vectorizer.fit_transform(X_train).toarray()\n",
        "X_test_BOW = vectorizer.transform(X_test).toarray()\n",
        "\n",
        "X_train_BOW[0].shape"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "construct training and testing appraisal feature matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(23642, 30)"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train_appraisal = np.array(\n",
        "    [appraisal_features(document) for document in X_train]\n",
        ")\n",
        "\n",
        "X_train_appraisal.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(5911, 30)"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_test_appraisal = np.array(\n",
        "    [appraisal_features(document) for document in X_test]\n",
        ")\n",
        "\n",
        "X_test_appraisal.shape"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Features' union"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(23642, 24772)\n",
            "(5911, 24772)\n"
          ]
        }
      ],
      "source": [
        "X_train = np.hstack((X_train_BOW, X_train_appraisal))\n",
        "X_test  = np.hstack((X_test_BOW, X_test_appraisal))\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Performance evaluation\n",
        "## Naive bayes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 58.53%\n",
            "Precesion : 55.61%\n",
            "Recall : 75.55%\n",
            "F1 score : 64.07%\n"
          ]
        }
      ],
      "source": [
        "if os.path.exists(\"./models/ASTC/APPRAISAL/NB.pkl\"):\n",
        "    # read model from disk\n",
        "    model = open(\"./models/ASTC/APPRAISAL/NB.pkl\", 'rb').read()\n",
        "    model: GaussianNB = pickle.loads(model)\n",
        "else:\n",
        "    model = GaussianNB()\n",
        "    model.fit(X_train, y_train)\n",
        "    # write model to disk\n",
        "    mdl_bytes = pickle.dumps(model)\n",
        "    open(\"./models/ASTC/APPRAISAL/NB.pkl\", 'wb').write(mdl_bytes)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision, recall, f1_score, _ = precision_recall_fscore_support(y_test, y_pred, average='binary', pos_label=\"pos\")\n",
        "\n",
        "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
        "print(f\"Precesion : {precision * 100:.2f}%\")\n",
        "print(f\"Recall : {recall * 100:.2f}%\")\n",
        "print(f\"F1 score : {f1_score * 100:.2f}%\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Logistic regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r_N8hCmIEEtK",
        "outputId": "7fd72e2e-c809-445a-851d-035c5e8381eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 87.50%\n",
            "Precesion : 85.21%\n",
            "Recall : 90.08%\n",
            "F1 score : 87.58%\n"
          ]
        }
      ],
      "source": [
        "if os.path.exists(\"./models/ASTC/APPRAISAL/LR.pkl\"):\n",
        "    # read model from disk\n",
        "    model = open(\"./models/ASTC/APPRAISAL/LR.pkl\", 'rb').read()\n",
        "    model: LogisticRegression = pickle.loads(model)\n",
        "else:\n",
        "    model = LogisticRegression(random_state = SEED, max_iter = 1500)\n",
        "    model.fit(X_train, y_train)\n",
        "    # write model to disk\n",
        "    mdl_bytes = pickle.dumps(model)\n",
        "    open(\"./models/ASTC/APPRAISAL/LR.pkl\", 'wb').write(mdl_bytes)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision, recall, f1_score, _ = precision_recall_fscore_support(y_test, y_pred, average='binary', pos_label=\"pos\")\n",
        "\n",
        "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
        "print(f\"Precesion : {precision * 100:.2f}%\")\n",
        "print(f\"Recall : {recall * 100:.2f}%\")\n",
        "print(f\"F1 score : {f1_score * 100:.2f}%\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### SVM\n",
        "\n",
        "We were unable to train this model on our machines using the initial dataset, due to the **curse of dimensionality**, so we added dimensioanlity reduction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 86.84%\n",
            "Precesion : 82.48%\n",
            "Recall : 92.81%\n",
            "F1 score : 87.34%\n"
          ]
        }
      ],
      "source": [
        "if os.path.exists(\"./models/ASTC/APPRAISAL/SVM_Pipeline.pkl\"):\n",
        "    # read pipeline from disk\n",
        "    pipeline = open(\"./models/ASTC/APPRAISAL/SVM_Pipeline.pkl\", 'rb').read()\n",
        "    pipeline = pickle.loads(pipeline)\n",
        "else:\n",
        "    steps = [\n",
        "        ('pca', PCA(n_components = 150, random_state = SEED)),\n",
        "        ('svm', SVC(random_state = SEED))\n",
        "    ]\n",
        "    pipeline = Pipeline(steps = steps)\n",
        "    pipeline.fit(X_train, y_train)\n",
        "    # write pipeline to disk\n",
        "    pipeline_bytes = pickle.dumps(pipeline)\n",
        "    open(\"./models/ASTC/APPRAISAL/SVM_Pipeline.pkl\", 'wb').write(pipeline_bytes)\n",
        "\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision, recall, f1_score, _ = precision_recall_fscore_support(y_test, y_pred, average='binary', pos_label = \"pos\")\n",
        "\n",
        "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
        "print(f\"Precesion : {precision * 100:.2f}%\")\n",
        "print(f\"Recall : {recall * 100:.2f}%\")\n",
        "print(f\"F1 score : {f1_score * 100:.2f}%\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Random forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 86.84%\n",
            "Precesion : 82.48%\n",
            "Recall : 92.81%\n",
            "F1 score : 87.34%\n"
          ]
        }
      ],
      "source": [
        "if os.path.exists(\"./models/ASTC/APPRAISAL/RF.pkl\"):\n",
        "    # read model from disk\n",
        "    model = open(\"./models/ASTC/APPRAISAL/RF.pkl\", 'rb').read()\n",
        "    model = pickle.loads(model)\n",
        "else:\n",
        "    model = RandomForestClassifier(random_state = SEED)\n",
        "    model.fit(X_train, y_train)\n",
        "    # write model to disk\n",
        "    mdl_bytes = pickle.dumps(model)\n",
        "    open(\"./models/ASTC/APPRAISAL/RF.pkl\", 'wb').write(mdl_bytes)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision, recall, f1_score, _ = precision_recall_fscore_support(y_test, y_pred, average='binary', pos_label=\"pos\")\n",
        "\n",
        "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
        "print(f\"Precesion : {precision * 100:.2f}%\")\n",
        "print(f\"Recall : {recall * 100:.2f}%\")\n",
        "print(f\"F1 score : {f1_score * 100:.2f}%\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Using appraisal features only (G:AO)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Naive bayes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 51.14%\n",
            "Precesion : 50.04%\n",
            "Recall : 95.30%\n",
            "F1 score : 65.62%\n"
          ]
        }
      ],
      "source": [
        "if os.path.exists(\"./models/ASTC/APPRAISAL/GAO/NB.pkl\"):\n",
        "    # read model from disk\n",
        "    model = open(\"./models/ASTC/APPRAISAL/GAO/NB.pkl\", 'rb').read()\n",
        "    model: GaussianNB = pickle.loads(model)\n",
        "else:\n",
        "    model = GaussianNB()\n",
        "    model.fit(X_train_appraisal, y_train)\n",
        "    # write model to disk\n",
        "    mdl_bytes = pickle.dumps(model)\n",
        "    open(\"./models/ASTC/APPRAISAL/GAO/NB.pkl\", 'wb').write(mdl_bytes)\n",
        "\n",
        "y_pred = model.predict(X_test_appraisal)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision, recall, f1_score, _ = precision_recall_fscore_support(y_test, y_pred, average='binary', pos_label=\"pos\")\n",
        "\n",
        "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
        "print(f\"Precesion : {precision * 100:.2f}%\")\n",
        "print(f\"Recall : {recall * 100:.2f}%\")\n",
        "print(f\"F1 score : {f1_score * 100:.2f}%\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Lostic regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 64.86%\n",
            "Precesion : 80.12%\n",
            "Recall : 37.48%\n",
            "F1 score : 51.07%\n"
          ]
        }
      ],
      "source": [
        "if os.path.exists(\"./models/ASTC/APPRAISAL/GAO/LR.pkl\"):\n",
        "    # read model from disk\n",
        "    model = open(\"./models/ASTC/APPRAISAL/GAO/LR.pkl\", 'rb').read()\n",
        "    model: LogisticRegression = pickle.loads(model)\n",
        "else:\n",
        "    model = LogisticRegression(random_state = SEED, max_iter = 1500)\n",
        "    model.fit(X_train_appraisal, y_train)\n",
        "    # write model to disk\n",
        "    mdl_bytes = pickle.dumps(model)\n",
        "    open(\"./models/ASTC/APPRAISAL/GAO/LR.pkl\", 'wb').write(mdl_bytes)\n",
        "\n",
        "y_pred = model.predict(X_test_appraisal)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision, recall, f1_score, _ = precision_recall_fscore_support(y_test, y_pred, average='binary', pos_label=\"pos\")\n",
        "\n",
        "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
        "print(f\"Precesion : {precision * 100:.2f}%\")\n",
        "print(f\"Recall : {recall * 100:.2f}%\")\n",
        "print(f\"F1 score : {f1_score * 100:.2f}%\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## SVM\n",
        "\n",
        "We were unable to train this model on our machines using the initial dataset, due to the **curse of dimensionality**, so we added dimensioanlity reduction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 64.73%\n",
            "Precesion : 80.13%\n",
            "Recall : 37.10%\n",
            "F1 score : 50.72%\n"
          ]
        }
      ],
      "source": [
        "if os.path.exists(\"./models/ASTC/APPRAISAL/GAO/SVM_Pipeline.pkl\"):\n",
        "    # read pipeline from disk\n",
        "    pipeline = open(\"./models/ASTC/APPRAISAL/GAO/SVM_Pipeline.pkl\", 'rb').read()\n",
        "    pipeline = pickle.loads(pipeline)\n",
        "else:\n",
        "    steps = [\n",
        "        ('svm', SVC(random_state = SEED))\n",
        "    ]\n",
        "    pipeline = Pipeline(steps = steps)\n",
        "    pipeline.fit(X_train_appraisal, y_train)\n",
        "    # write pipeline to disk\n",
        "    pipeline_bytes = pickle.dumps(pipeline)\n",
        "    open(\"./models/ASTC/APPRAISAL/GAO/SVM_Pipeline.pkl\", 'wb').write(pipeline_bytes)\n",
        "\n",
        "y_pred = pipeline.predict(X_test_appraisal)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision, recall, f1_score, _ = precision_recall_fscore_support(y_test, y_pred, average='binary', pos_label = \"pos\")\n",
        "\n",
        "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
        "print(f\"Precesion : {precision * 100:.2f}%\")\n",
        "print(f\"Recall : {recall * 100:.2f}%\")\n",
        "print(f\"F1 score : {f1_score * 100:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Random forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 64.73%\n",
            "Precesion : 80.13%\n",
            "Recall : 37.10%\n",
            "F1 score : 50.72%\n"
          ]
        }
      ],
      "source": [
        "if os.path.exists(\"./models/ASTC/APPRAISAL/GAO/RF.pkl\"):\n",
        "    # read model from disk\n",
        "    model = open(\"./models/ASTC/APPRAISAL/GAO/RF.pkl\", 'rb').read()\n",
        "    model = pickle.loads(model)\n",
        "else:\n",
        "    model = RandomForestClassifier(random_state = SEED)\n",
        "    model.fit(X_train_appraisal, y_train)\n",
        "    # write model to disk\n",
        "    mdl_bytes = pickle.dumps(model)\n",
        "    open(\"./models/ASTC/APPRAISAL/GAO/RF.pkl\", 'wb').write(mdl_bytes)\n",
        "\n",
        "y_pred = pipeline.predict(X_test_appraisal)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision, recall, f1_score, _ = precision_recall_fscore_support(y_test, y_pred, average='binary', pos_label=\"pos\")\n",
        "\n",
        "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
        "print(f\"Precesion : {precision * 100:.2f}%\")\n",
        "print(f\"Recall : {recall * 100:.2f}%\")\n",
        "print(f\"F1 score : {f1_score * 100:.2f}%\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Serialize data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [],
      "source": [
        "from appraisal import AppraisalUtils\n",
        "\n",
        "utils = AppraisalUtils(lexicon, word_to_appraisal_grp, appraisal_grp_to_idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "6592"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "open(\"./models/ASTC/APPRAISAL/vectorizer.pkl\", \"wb\").write(pickle.dumps(utils))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
